\section{Introduction}
Cloud computing abstracts physical infrastructure into dynamic, ephemeral resources, creating a computational model distinct from traditional on-premise environments.
Ensuring workload integrity across cloud instances and large-scale HPC clusters is critical, as operators must prevent unauthorized modifications across thousands of nodes. 
However, modern applications introduce a tension between security and agility, as frequent deployments and updates cause massive file churn that renders traditional models ineffective.


To address this, two main strategies exist: File Integrity Monitoring (FIM) and Runtime Behavioral Analysis. FIM tools such as AIDE~\cite{aide} and Tripwire~\cite{tripwire} detect static changes through cryptographic hashes, while runtime monitors such as Falco~\cite{falco} and OSSEC~\cite{ossec} trace system calls for anomalies. However, traditional integrity verification faces a fundamental scalability challenge. As the number of files ($N$) grows, the scan latency increases linearly ($O(N)$), causing severe I/O bottlenecks in hyperscale storage. This is problematic because modern cloud instances, despite high CPU throughput, have limited storage bandwidth. For example, scanning a filesystem with millions of small files using synchronous system calls results in excessive context switching and blocking I/O. Beyond the performance cost, the alert fatigue problem further limits usability, as legitimate updates generate thousands of false positives, masking true threats~\cite{arp2022dos}. Thus, the operational cost exceeds the theoretical benefit, forcing operators to disable monitoring during maintenance windows which can create a loophole that attackers can exploit.


\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{Figures/fig_motivation_legend.pdf}
\vspace{-0.5cm} % Restore legend visibility
\subfloat[Scalability]{
    \includegraphics[width=0.47\columnwidth]{Figures/fig_motivation_a.pdf}
}
\hfill
\subfloat[Alert Fatigue]{
    \includegraphics[width=0.47\columnwidth]{Figures/fig_motivation_b.pdf}
}
\vspace{5mm}
\caption{(a) \DeepVis achieves high-throughput saturation via async I/O. (b) Legitimate updates generate false alerts in AIDE.}
\label{fig:motivation}
\end{figure}

Figure~\ref{fig:motivation} compares the scalability and precision of an existing FIM tool (i.e., AIDE) with the proposed scheme (i.e., \DeepVis). We used a cloud instance from a real cloud system as described in Section~\ref{eval_setup} and performed a user directory scan. The AIDE scan time increases linearly with a steep slope, exceeding four minutes for only 100K files. This behavior results from synchronous I/O operations and full file reads required to compute hash values and detect all changes since the latest snapshot. In contrast, \DeepVis reads only the first 4 KB of each file and uses a parallelized asynchronous pipeline to saturate storage bandwidth, keeping scan times under seven seconds for the same dataset. Although file ingestion remains physically \(O(N)\), \DeepVis achieves an effective speedup of up to 121.45$\times$ over traditional full-hash baselines and 16.38$\times$ over modified full-hash schemes that read the same amount of data due to its efficient I/O design. Crucially, \DeepVis ensures that subsequent anomaly detection (Inference) time remains constant regardless of dataset size.



\begin{table}[t]
\caption{Comparison with prior work across four key capabilities: Asynchronous I/O (Async), Obfuscation Resilience (Obfusc.), Zero-Day Detection (0-Day), and Low Overhead (Low Ovhd.).}
\centering
\scriptsize
\begin{tabular}{p{1.5cm}|>{\raggedright\arraybackslash}p{1.6cm}|c|c|c|c}
\toprule
\textbf{Study} & \textbf{Approach} & \textbf{Asnc} & \textbf{Obfs.} & \textbf{0-Day} & \textbf{Low} \\
\midrule
AIDE~\cite{aide} & Full-Hash FIM &  & \checkmark &  &  \\
Tripwire~\cite{tripwire} & Full-Hash FIM &  & \checkmark &  &  \\
ClamAV~\cite{clamav} & Signature Scanning &  &  &  & \checkmark \\
Falco~\cite{falco} & Runtime/eBPF & \checkmark &  & \checkmark &  \\
Unicorn~\cite{unicorn} & Provenance Graph &  & \checkmark & \checkmark &  \\
OSSEC~\cite{ossec} & Log Analysis &  &  &  & \checkmark \\
Set-AE~\cite{zaheer2017deepsets} & Deep Sets Learning & \checkmark & \checkmark & \checkmark & \checkmark \\
\hline
\textbf{\DeepVis} & \textbf{Hash-Grid Tensor} & \checkmark & \checkmark & \checkmark & \checkmark \\
\bottomrule
\end{tabular}
\label{tab:intro_comparison}
\end{table}

Many previous studies, as summarized in Table~\ref{tab:intro_comparison}, have explored works to enhance the scalability of system monitoring. Several works~\cite{aide, tripwire} focus on cryptographic exactness but suffer from $O(N)$ scalability limits. Runtime approaches~\cite{falco, unicorn} utilize eBPF or provenance graphs to detect zero-day threats but suffer from \textit{state loss risks}: if the monitoring agent crashes or is bypassed by a kernel-level rootkit, the modification event is lost forever. Deep learning-based approaches, such as Set-AE~\cite{zaheer2017deepsets}, attempt to learn system states but fail to detect sparse anomalies due to signal dilution in global pooling.

\DeepVis distinguishes itself from prior works by departing from both sequential scanning and global pooling. Most previous studies rely on unordered set processing or linear file walking, which constrains performance to file count or dilutes attack signals. In contrast, \DeepVis adopts a \textbf{Hash-Based Spatial Representation} that maps unordered files to a fixed-size 2D tensor. By ensuring shift invariance via deterministic hashing, \DeepVis enables the use of Convolutional Neural Networks (CNNs) to process the file system as an image. Furthermore, it addresses the \textit{MSE Paradox}—where diffuse update noise masks sparse attack signals—by utilizing Local Max ($L_\infty$) detection. This allows \DeepVis to isolate specific anomalies without being affected by the global noise floor.

In this paper, we propose \DeepVis, a highly scalable integrity verification framework designed for hyperscale distributed systems. 
\DeepVis provides file system abstraction and anomaly detection through \textbf{Deep} learning-based \textbf{Vis}ualization.
Using header-only read apporach, \DeepVis offers lightweight scalability required for cloud systems and dectection through abnormal header contents and paths.
Specifically, \DeepVis (1) transforms file metadata into a fixed-size tensor using hash-based partitioning to achieve $O(1)$ inference latency, (2) utilizes a Hash-Grid Parallel CAE with Local Max detection to pinpoint sparse anomalies amidst system churn, and (3) employs an asynchronous \texttt{io\_uring} snapshot engine to maximize I/O throughput. 
We explicitly position \DeepVis as a \textbf{High-Speed Binary Audit} tool, distinct from text-based script scanners. While signature-based tools (e.g., YARA) effectively detect script attacks, they often fail against packed binaries and kernel rootkits that obfuscate their payloads. \DeepVis acts as a complementary layer, detecting the \textit{structural anomalies} inherent in these hidden executables. Furthermore, unlike incremental monitors (e.g., \texttt{fanotify}) that can miss events if the agent crashes or is bypassed, \DeepVis performs absolute state verification. Its high throughput (10.9$\times$ faster than FIM) makes frequent "cold-start" auditing feasible, ensuring system integrity regardless of prior monitoring gaps.