\section{Introduction}
\label{Introduction}

In distributed systems, file system consistency is critical. Container orchestration platforms such as Kubernetes and Docker Swarm, cloud storage services such as AWS EBS and Azure Files, and HPC clusters rely on verified file system state for security and reliability. However, modern DevOps practices create a fundamental tension. Traditional File Integrity Monitoring (FIM) tools generate thousands of alerts on every system update which overwhelms operators. Meanwhile, anomaly detection methods fail because file systems are non-Euclidean data structures lacking inherent spatial ordering.

Consider a routine scenario where an administrator executes an update command on an Ubuntu server. This operation modifies several thousand files including libraries, configuration snippets, and binaries. For traditional FIM tools such as AIDE~\cite{aide} or Tripwire~\cite{tripwire}, each modification triggers an alert. Security Operations Centers (SOCs) face an impossible choice. They must either investigate thousands of false positives daily which leads to Alert Fatigue or disable FIM during maintenance windows. This creates blind spots exploited by advanced persistent threats. Neither option is acceptable for production systems.

To overcome the limitations of traditional monitoring, researchers have proposed log-based and provenance-based detection methods. However, these approaches face fundamental scalability challenges in hyperscale environments. Traditional tools such as \textit{AIDE}~\cite{aide} exhibit linear $O(N)$ complexity, requiring over five minutes to verify one million files---unacceptable for real-time verification. Provenance-based methods such as \textit{Kairos}~\cite{cheng2024kairos} achieve high precision but impose 5--20\% runtime overhead due to kernel instrumentation. Machine learning approaches typically fail due to the Shift Problem where a single file addition destabilizes the entire learned representation. To summarize, addressing the poor scalability of FIM and the high overhead of provenance systems, our work (\DeepVis) aims to provide constant-time performance regardless of the file count while maintaining zero runtime overhead.

% TODO: Add scalability comparison figure
% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=10.5cm]{figures/intro_scalability_comparison.png}
%     \caption{Verification latency of \DeepVis (Proposed), Traditional FIM (\textit{AIDE}), and Provenance Systems (\textit{Kairos}). \DeepVis maintains constant $O(1)$ latency while others scale linearly.}
%     \label{intro_data_overall}
% \end{figure}

\begin{table}[t]
    \captionsetup{skip=2pt}
    \caption{Comparison with previous monitoring paradigms. (O(1): Constant Inference, ZRO: Zero Runtime Overhead, UT: Update Tolerance).}
    \centering
    \scriptsize
    \begin{tabular}{l|l|c|c|c}
        \toprule \textbf{Framework} & \textbf{Method} & \textbf{O(1)} & \textbf{ZRO} & \textbf{UT} \\
        \midrule 
        AIDE~\cite{aide} & File Hashing & & \checkmark & \\
        Tripwire~\cite{tripwire} & File Hashing & & \checkmark & \\
        DeepLog~\cite{du2017deeplog} & Log Sequence & & \checkmark & \checkmark \\
        Unicorn~\cite{unicorn} & Provenance Graph & & & \checkmark \\
        Kairos~\cite{cheng2024kairos} & Provenance Graph & & & \checkmark \\
        Flash~\cite{flash2024} & FS Graph & & & \checkmark \\
        \textbf{\DeepVis} & \textbf{Spatial Tensor} & \textbf{\checkmark} & \textbf{\checkmark} & \textbf{\checkmark} \\
        \bottomrule
    \end{tabular}
    \label{intro_table}
\end{table}

Many previous studies, as shown in Table~\ref{intro_table}, have focused on optimizing system monitoring from different architectural perspectives. For example, traditional FIM tools~\cite{aide, tripwire} rely on exhaustive hashing which suffers from $O(N)$ complexity bottlenecks. Log-based approaches~\cite{du2017deeplog} analyze temporal sequences but lack spatial awareness of the file system state. They cannot detect file-based persistence without corresponding log events. Provenance-based methods~\cite{unicorn, cheng2024kairos, flash2024} build causal graphs from system calls to detect anomalies. While powerful, they require heavy kernel instrumentation (e.g., \texttt{auditd} or CamFlow) which imposes 5--20\% runtime overhead. This overhead renders them infeasible for latency-sensitive workloads such as high-frequency trading or real-time gaming servers.

\DeepVis distinguishes itself from previous studies by implementing the first spatial representation learning framework for distributed file systems. Previous studies typically treat file systems as unordered lists or graphs which leads to the Shift Problem. Sorting files by path introduces catastrophic fragility where installing a single package shifts every subsequent file in the representation. In contrast, \DeepVis adopts a novel Hash-Based Spatial Mapping strategy. It maps unordered file systems to fixed-size 2D tensors via deterministic hash-based coordinates. This ensures shift invariance so that adding one file does not perturb the entire representation. Furthermore, we address the MSE Paradox where legitimate updates produce high global error while stealthy rootkits produce low global error. We utilize Local Max Detection ($L_\infty$) to isolate sparse anomalies regardless of global noise.

In this paper, we present \DeepVis, a highly scalable integrity verification framework designed for hyperscale distributed systems. \DeepVis adopts a spatial snapshot approach and integrates three key techniques to achieve scalability and precision. The goal of \DeepVis is to 1) decouple inference complexity from the file count, 2) resolve the statistical asymmetry between diffuse updates and sparse attacks, and 3) eliminate runtime overhead on the host kernel. To achieve these goals, \DeepVis 1) transforms file metadata into a fixed-size tensor using hash-based partitioning, 2) utilizes a Convolutional Autoencoder with Local Max detection to identify spatial anomalies, and 3) operates on storage snapshots to ensure zero impact on running workloads. Our evaluation on production infrastructure across Ubuntu, CentOS, and Debian demonstrates that \DeepVis achieves an F1-score of 0.96 with zero false positives and enables 168$\times$ more frequent monitoring than traditional FIM. 