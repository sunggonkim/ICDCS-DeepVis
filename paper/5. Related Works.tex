\section{Related Work}
\label{sec:related_work}

\noindent\textbf{Scalable Integrity and Cloud-Native Monitoring. }
Optimizing system integrity monitoring requires balancing security depth with performance overhead. Traditional File Integrity Monitoring (FIM) tools~\cite{tripwire, aide, samhain} rely on cryptographic hashing to detect unauthorized modifications. While effective for static environments, they suffer from linear $O(N)$ complexity, making them prohibitive for hyperscale cloud environments. To address real-time constraints, provenance-based systems~\cite{unicorn, cheng2024kairos} and runtime monitors~\cite{ossec, falco} track information flow and system calls. Recent advancements leverage eBPF to reduce monitoring overhead and harden isolation~\cite{he2023cross, tfjmp2024safebpf}. However, even lightweight eBPF probes incur continuous CPU costs due to event interception and cannot detect dormant threats implanted prior to monitoring (the cold-start problem). In contrast, \DeepVis eliminates runtime instrumentation overhead by operating on asynchronous storage snapshots, decoupling the monitoring cost from the active workload while providing coverage for dormant artifacts.

\noindent\textbf{Kernel-Anchored Integrity Attestation. }
Beyond user-space scanning, the Linux kernel provides native integrity subsystems such as the Integrity Measurement Architecture (IMA) and Extended Verification Module (EVM)~\cite{zohar2018integrity}. These frameworks utilize cryptographic Merkle trees~\cite{oprea2007integrity} and hardware-backed TPMs to enforce strict allow-listing and immutable remote attestation. While offering strong trust guarantees, they introduce significant operational rigidity in ephemeral environments. Research highlights that IMA faces challenges in containerized deployments due to namespace isolation conflicts and potential privacy leakage~\cite{luo2019container}, while complex policy management often leaves the system vulnerable to subversion or TOCCTOU (Time-of-Check-to-Time-of-Use) attacks~\cite{bohling2020subverting}. Consequently, \DeepVis serves as a lightweight, user-space complement to these rigid frameworks, enabling high-frequency verification and visual triage without requiring kernel reconfiguration or hardware dependencies.

\noindent\textbf{Malware Visualization and Adversarial Evasion. }
Treating binary analysis as a computer vision problem allows systems to bypass the brittleness of signature-based detection. Prior studies~\cite{nataraj2011malware, conti2008visual, aldini2024image} demonstrate that mapping binary files to grayscale images or space-filling curves reveals structural patterns distinct to malware families. Similarly, entropy analysis~\cite{lyda2007entropy} identifies packed or encrypted payloads with high information density. However, sophisticated adversaries increasingly employ evasion techniques, such as padding or mimicry, to fool learning-based detectors~\cite{ling2024wolf, uetz2024detecting}. \DeepVis addresses these challenges by extending single-file visualization to \textit{whole-system fingerprinting}. Instead of relying on a single metric susceptible to padding, \DeepVis maps the entire file system into a fixed-size RGB tensor. By encoding Entropy (Red), Context (Green), and Structure (Blue) into a spatial grid, the system leverages feature orthogonality to detect sparse anomalies that evade uni-modal analysis.

\noindent\textbf{Deep Learning for Anomaly Detection. }
Deep learning is widely adopted for detecting anomalies in high-dimensional system data. Approaches such as DeepLog~\cite{du2017deeplog} use LSTM networks to model system logs, while Kitsune~\cite{mirsky2018kitsune} employs autoencoders for network intrusion detection. For high-dimensional tabular or sensor data, unsupervised frameworks such as Deep One-Class Classification~\cite{ruff2018deep}, GANomaly~\cite{akcay2018ganomaly}, and DAGMM~\cite{zong2018deep} learn normal data distributions to flag outliers. Additionally, VAE-based models~\cite{su2019robust, xu2018unsupervised} are effective for multivariate time-series data. However, these methods typically rely on temporal sequences or fixed feature sets. File systems present a unique "Ordering Problem" as they are unordered sets of variable-length paths. \DeepVis resolves this by employing a deterministic spatial hash mapping and Local Max Detection ($L_\infty$), enabling the application of convolutional autoencoders to unordered system states without the signal dilution associated with global pooling.