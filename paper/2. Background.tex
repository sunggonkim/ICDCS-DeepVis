\section{Background}~\label{Background}

In this section, we provide essential background on File Integrity Monitoring and formalize the core challenges that motivate \DeepVis.

\subsection{File Integrity Monitoring}

File Integrity Monitoring (FIM) is a security technique that monitors and validates system files to detect unauthorized changes. The fundamental principle is simple: compute a cryptographic hash of each monitored file, store it in a secure database, and periodically compare current hashes against the baseline.

\subsubsection{Traditional Approaches}

\noindent\textbf{AIDE (Advanced Intrusion Detection Environment)~\cite{aide}} is the de facto standard for Linux FIM. It maintains a database of file attributes (hash, permissions, size, timestamps) and reports any deviations. AIDE is highly configurable, allowing administrators to define custom rules for different directories.

\noindent\textbf{Tripwire~\cite{tripwire}} pioneered the FIM concept in 1992. It introduced the notion of a ``policy file'' that specifies which attributes to monitor for each file category.

\noindent\textbf{OSSEC~\cite{ossec}} integrates FIM with log analysis and active response, providing a more comprehensive HIDS solution.

\subsubsection{Limitations of Traditional FIM}

While effective for static servers, traditional FIM suffers from a fundamental limitation: \textbf{any change generates an alert}. In dynamic environments with frequent updates, this leads to:

\begin{itemize}
    \item \textbf{Alert Fatigue:} A kernel upgrade modifies thousands of files, generating thousands of alerts.
    \item \textbf{Frequent Re-baselining:} Administrators must constantly update the baseline database, creating operational overhead.
    \item \textbf{Maintenance Windows:} FIM is often disabled during updates, creating blind spots.
\end{itemize}

\subsection{The Shift Problem}

To apply machine learning to file system analysis, one must first represent the file system state as a feature vector or tensor. The naive approach is to sort files (by path or size) and concatenate their attributes.

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{Figures/shift_problem.png}
    \vspace{-0.6cm}
    \caption{The Shift Problem. Adding a single file shifts all subsequent pixel positions, confusing the CNN.}
    \label{fig:shift_problem}
    \vspace{-.6cm}
\end{figure}

Figure~\ref{fig:shift_problem} illustrates the problem. Consider a sorted list of files: $[f_1, f_2, f_3, \dots, f_n]$. If a new file $f_{new}$ is inserted such that $f_{new} < f_2$ alphabetically, the resulting list becomes $[f_1, f_{new}, f_2, f_3, \dots, f_n]$. Every file after $f_1$ has shifted position.

For a CNN trained on the original representation, this shift is catastrophic:
\begin{itemize}
    \item The pixel corresponding to $f_2$ now contains data from $f_{new}$.
    \item Learned spatial patterns are destroyed.
    \item A benign file addition appears as a global anomaly.
\end{itemize}

\noindent\textbf{Definition (Shift-Invariance):} A representation $R: \mathcal{F} \rightarrow \mathbb{R}^{H \times W}$ is \textit{shift-invariant} if for all $f_i \in \mathcal{F}$ and all $f_{new} \notin \mathcal{F}$:
\begin{equation}
    R(\mathcal{F})_{x_i, y_i} = R(\mathcal{F} \cup \{f_{new}\})_{x_i, y_i}
\end{equation}
where $(x_i, y_i)$ is the coordinate assigned to $f_i$.

Traditional sorting-based representations violate this property. \DeepVis achieves shift-invariance through hash-based coordinate assignment.

\subsection{The MSE Paradox}

The Mean Squared Error (MSE) is the standard loss function for autoencoders:
\begin{equation}
    \mathcal{L}_{MSE} = \frac{1}{N} \sum_{i=1}^{N} || X_i - \hat{X}_i ||^2
\end{equation}

Intuitively, one expects anomalous inputs to produce higher reconstruction error. However, our experiments reveal a counter-intuitive phenomenon we term the \textbf{MSE Paradox}.

\begin{table}[t]
\centering
\caption{The MSE Paradox: Global vs. Local Error}
\label{tab:mse_paradox}
\begin{tabular}{lcc}
\toprule
\textbf{Scenario} & \textbf{Global MSE} & \textbf{Local Max} \\
\midrule
Static System & 0.001 & 0.05 \\
apt-get upgrade & \textbf{0.048} & 0.65 \\
Diamorphine Rootkit & 0.039 & \textbf{0.99} \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:mse_paradox} shows representative measurements:
\begin{itemize}
    \item \textbf{Legitimate Update:} Modifies thousands of files, producing high \textit{aggregate} MSE (0.048).
    \item \textbf{Rootkit Injection:} Modifies a single kernel module, producing low aggregate MSE (0.039) but extreme \textit{local} deviation (0.99).
\end{itemize}

\noindent\textbf{Implication:} Global thresholds systematically fail. A detector using $MSE > 0.04$ as the threshold would:
\begin{enumerate}
    \item Flag every legitimate update as malicious (False Positive).
    \item Potentially miss rootkits if their MSE falls below the threshold (False Negative).
\end{enumerate}

\DeepVis overcomes this paradox by using \textit{Local Max Difference} as the detection metric, which captures point anomalies regardless of global noise.

\subsection{Shannon Entropy as a Malware Indicator}

Shannon Entropy measures the randomness of a byte sequence:
\begin{equation}
    S(f) = -\sum_{b=0}^{255} p_b \log_2 p_b
\end{equation}
where $p_b$ is the probability of byte value $b$ in file $f$.

Prior work~\cite{lyda2007entropy} has established that:
\begin{itemize}
    \item \textbf{Typical ELF binaries:} $S \approx 5.0$ -- $6.0$
    \item \textbf{Text/Config files:} $S \approx 4.0$ -- $5.0$
    \item \textbf{Packed/Encrypted malware:} $S > 7.0$
\end{itemize}

Rootkits are often packed (e.g., UPX) or encrypted to evade signature-based detection. This raises their entropy to near-maximum values (8.0 for pure random data). \DeepVis exploits this by encoding entropy in the Red channel, making high-entropy files visually prominent.
