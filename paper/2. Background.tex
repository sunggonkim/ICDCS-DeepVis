

\section{Background}
\label{sec:background}




\subsection{Integrity Verification at Cloud Scale}

Modern cloud infrastructure requires file integrity monitoring that balances scalability, detection coverage, and operational overhead~\cite{aide,tripwire,samhain,falco,unicorn}. Current solutions divide into file-level scanning and runtime behavioral analysis, each with distinct limitations.

\noindent\textbf{File-level integrity scanning.} AIDE~\cite{aide} and Tripwire~\cite{tripwire} establish integrity through cryptographic hashes of entire files compared against known baselines. While effective for static environments, their $O(N \times Size)$ complexity becomes prohibitive in dynamic hyperscale systems. Full scans routinely exceed maintenance windows, necessitating temporary monitoring disablement. Moreover, routine updates produce massive false positive alerts that burden Security Operations Centers.

\noindent\textbf{Runtime behavioral analysis.} Falco~\cite{falco} and provenance graph systems~\cite{unicorn} intercept kernel events to detect anomalous execution patterns. These approaches incur substantial continuous overhead (5-20\% CPU) from pervasive instrumentation. A critical limitation is their event-based nature: they cannot detect threats predating monitor deployment, creating the cold-start vulnerability for persistent rootkits.

File-level scanning remains essential for compliance validation, image verification, and forensic analysis due to its comprehensive state coverage. However, synchronous sequential processing causes I/O bottlenecks and operational overload at scale. \DeepVis overcomes these constraints using asynchronous I/O, spatial hash mapping, and neural anomaly detection for production-grade filesystem integrity.


\begin{figure*}[!t]
    \centering
    \subfloat[Combined]{
        \includegraphics[width=0.45\columnwidth]{Figures/Background_entrophy/entropy_combined_a.pdf}
        \label{fig:entropy_hist}
    }%
    \hfill
    \subfloat[Text]{
        \includegraphics[width=0.45\columnwidth]{Figures/Background_entrophy/Background_Normal_text.pdf}
        \label{fig:entropy_text}
    }
    \hfill
    \subfloat[ELF Binary]{
        \includegraphics[width=0.45\columnwidth]{Figures/Background_entrophy/Background_System_binaray.pdf}
        \label{fig:entropy_elf}
    }%
    \hfill
    \subfloat[Packed Rootkit]{
        \includegraphics[width=0.45\columnwidth]{Figures/Background_entrophy/Background_Rootkit.pdf}
        \label{fig:entropy_rootkit}
    }
    \caption{File fingerprint analysis via byte-value histograms. (a) Combined entropy distribution across file types. (b) Text files use only printable ASCII, resulting in low entropy ($H \approx 4.8$) and zero null bytes. (c) ELF binaries show structured headers with significant zero-padding (40--85\% null bytes) for section alignment, yielding $H \approx 6.0$. (d) Packed rootkits eliminate all structure and null bytes ($<$1\%), maximizing entropy near the theoretical limit ($H \approx 8.0$).}
    \label{fig:entropy_combined}
\end{figure*}


\subsection{The Attacker Paradox: Entropy and Structure}


To effectively detect evasive malware without relying on fragile signatures, it is essential to analyze the statistical properties of binary files. Modern malware authors face a fundamental trade-off between concealing their code and maintaining the structural validity required by the operating system loader. We identify two orthogonal dimensions that distinguish malicious payloads from benign system files: Entropy and Structural Density.

Figure~\ref{fig:entropy_combined} illustrates these statistical differences through byte-value histograms across varying file types. Text files (Figure~\ref{fig:entropy_combined}b) exhibit a characteristic spike in the printable ASCII range, yielding low entropy ($H \approx 4.8$) with zero null bytes due to high redundancy. Legitimate ELF binaries (Figure~\ref{fig:entropy_combined}c) show a prominent peak at 0x00, resulting from section alignment padding, a structural requirement imposed by the operating system to align memory pages. This creates moderate entropy ($H \approx 6.0$) with significant zero-padding concentrations (40--85\% null bytes). In contrast, packed or encrypted malware (Figure~\ref{fig:entropy_combined}d) displays a nearly uniform distribution across all byte values. As compression algorithms remove redundancy and encryption approximates randomness, the byte distribution flattens significantly, approaching maximum entropy ($H \approx 8.0$) with minimal null bytes ($<$1\%).

\noindent\textbf{The Attacker Paradox.} This distinction reveals a fundamental vulnerability in malware design. 
Native rootkits such as Diamorphine maintain structural stealth by mimicking the layout of legitimate binaries, ensuring OS loader compatibility. However, they remain vulnerable to signature-based detection tools such as YARA because their code contains known byte sequences. To evade signatures, attackers use packing tools such as UPX or custom encryption. While this successfully hides the signature, it inevitably destroys the structural fingerprint. 
As shown in Figure~\ref{fig:entropy_combined}, the packing process maximizes information density, pushing the Shannon entropy toward the theoretical limit of 8.0 bits per byte and eliminating the zero-padding signal. Consequently, an attacker must choose between exposing a signature or creating a statistical anomaly.

\noindent\textbf{Implications for Detection.} This paradox reveals a fundamental detection opportunity. Signature-based scanners succeed against native rootkits but fail against packed malware. Header-only heuristics catch compression artifacts but generate false positives on benign high-entropy files (compressed archives, encrypted configuration). Neither approach captures the full threat landscape without sacrificing precision. A multi-modal strategy that fuses entropy, structural markers, and contextual features can disambiguate these overlapping cases. Entropy identifies compression-based evasion, structural analysis exposes binary format violations, and contextual signals (path, permissions) distinguish legitimate outliers from malicious anomalies. This orthogonal feature space enables detection of threats regardless of whether attackers pursue signature evasion or structural stealth. Traditional integrity verification relies on sequential scanning, which ignores spatial risk concentrations and scales linearly with file count. Global pooling methods suffer from signal dilution, where a single malicious file drowns in the variance of thousands of benign entries. Detection becomes impossible when legitimate updates create diffuse noise exceeding any sparse attack signal. \DeepVis addresses these challenges by transforming the entire filesystem into a fixed-size tensor where multi-modal anomalies manifest as localized spikes, enabling per-pixel independence and fast inference regardless of system size.