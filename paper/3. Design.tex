\section{\DeepVis System Design}
\label{sec:design}

In this section, we present the design of \DeepVis, a scalable integrity verification framework for hyperscale cloud environments. \DeepVis does not rely on sequential file scanning or heavy kernel instrumentation, but instead employs a snapshot-based hybrid architecture that decouples metadata ingestion from anomaly detection. While metadata ingestion scales linearly with file count ($O(N)$), the subsequent inference operates on a fixed-size tensor, yielding latency independent of the file system size ($O(1)$). To overcome the I/O bottlenecks inherent in scanning millions of files, it utilizes a parallelized asynchronous pipeline for metadata collection and leverages a deterministic hash-based mapping to transform unordered file systems into fixed-size tensor representations.

\subsection{Overall Procedure}
\label{design_1}

Figure~\ref{fig:overall} shows the overall procedure of \DeepVis. \DeepVis provides two main phases to support distributed integrity verification: the \textit{Snapshot} phase and the \textit{Verification} phase.

\begin{figure}[t]
    \centering
    % [User Check] 파일명 유지함. 
    % 단, PDF 내용이 텍스트와 일치하는지(128x128 등) 확인 필요.
    \includegraphics[width=9cm]{Figures/Design/Overall_Arch.pdf}
    \caption{Overall procedure of \DeepVis. It illustrates the transformation of raw file system metadata into spatially mapped tensors, followed by reconstruction via an autoencoder and anomaly detection using Local Max ($L_\infty$) logic.}
    \label{fig:overall}
\end{figure}

\noindent
\textbf{Snapshot Phase.} When integrity verification starts, the data collection process is initiated. Unlike existing synchronous tools (e.g., \texttt{find} or \texttt{ls}) that block on every file access, \DeepVis utilizes a hybrid parallel architecture. Multiple worker threads traverse the directory tree and collect file paths (\ding{182}), feeding them into a lock-free queue. These paths are batched and submitted to the kernel using the \texttt{io\_uring} interface, ensuring that I/O throughput saturates the storage bandwidth rather than being latency-bound (\ding{183}).

After collecting raw metadata and file headers, secure spatial mapping is performed. A deterministic coordinate is calculated for each file using a Keyed-Hash Message Authentication Code (HMAC) (\ding{184}), and multi-modal features (entropy, permissions) are extracted (\ding{185}). These features are aggregated into a fixed-size 2D tensor ($128 \times 128 \times 3$), effectively transforming the file system state into an image-like representation (\ding{186}).

\noindent\textbf{Verification Phase.} After the first phase is completed, \DeepVis enters the verification phase. The generated tensor is fed into a pre-trained 1$\times$1 Convolutional Autoencoder (CAE). While standard CNNs exploit spatial locality to find shapes, the hash-based mapping lacks semantic neighborhood relationships. Therefore, 1$\times$1 Convolutions are employed not to extract spatial features, but to learn complex cross-channel non-linear correlations (e.g., distinguishing a high-entropy zip file in a user directory from a high-entropy packed binary in a system path). This effectively acts as a learnable, non-linear per-pixel thresholding mechanism (\ding{187}).

The pixel-wise difference between the input and reconstructed tensors is then computed. To resolve the statistical asymmetry between legitimate diffuse updates and sparse attacks, Local Max Detection ($L_\infty$) is utilized (\ding{188}). This mechanism isolates the single highest deviation in the grid. Finally, if the $L_\infty$ score exceeds a dynamically learned threshold, an alert is raised, identifying the presence of a stealthy anomaly such as a rootkit (\ding{189}).



\subsection{Asynchronous File System Traversal}
\label{design_2}

Before generating the tensor representation, \DeepVis processes metadata and file headers across thousands of cloud instances. Existing synchronous system calls (e.g., \texttt{stat}, \texttt{open}, \texttt{read}) cause context switching overhead and CPU blocking at scale. Network-attached storage in cloud environments exacerbates I/O latency. \DeepVis overcomes this with a hybrid pipeline separating CPU-bound path traversal from I/O-bound data reading.

\begin{figure}[t]
    \centering
    \includegraphics[width=8cm]{Figures/Design/io_Arch.pdf}
    \caption{Hybrid snapshot pipeline of \DeepVis using Rayon for parallel path collection and \texttt{io\_uring} for asynchronous I/O.}
    \label{fig:pipeline}
\end{figure}

\noindent\textbf{Parallel Path Collection.} \DeepVis uses work-stealing parallelism from the Rust \texttt{rayon} library for path collection.
As shown on the left of Figure~\ref{fig:pipeline}, the \textit{Path Collector Threadpool} spawns worker threads that execute synchronous \texttt{fs::read\_dir} operations recursively. This CPU-bound phase parses directory entries and builds path strings across all cores, filling the \textit{Pending Path Queue} faster than I/O consumption.

\noindent\textbf{Asynchronous I/O Processing.} With paths enqueued, reading file headers becomes the bottleneck. \DeepVis employs Linux \texttt{io\_uring} to eliminate per-file system call overhead. As shown in Figure~\ref{fig:pipeline}, the \textit{io\_uring Submitter} batches paths into Submission Queue (SQ) read requests (\texttt{OP\_READ}). Unlike traditional async I/O, \texttt{io\_uring} uses shared ring buffers for kernel-user communication. \textit{Data Processor} threads poll the Completion Queue (CQ) for finished reads. Completed events trigger data retrieval from pre-allocated \textit{Buffer Slab}s, followed by immediate hashing and entropy calculation. CPU threads never block on disk I/O. The kernel handles data movement while user-space processes features. This achieves throughput competitive with raw disk bandwidth.




\subsection{Header Sampling}
\label{design_sampling}

Traditional FIM tools hash entire files, causing massive I/O overhead ($O(N \times Size)$). Conversely, metadata-only scanning (e.g., file size, name) produces high false negatives against padded malware. To balance these extremes, \DeepVis adopts header-based entropy sampling.

As discussed in Section~\ref{sec:background}, packed malware and ransomware inevitably modify file headers to accommodate unpacker stubs or encrypted payloads, significantly increasing entropy in the first few blocks. To detect this, \DeepVis reads only the first 4KB of each file asynchronously. File systems use 4KB block size, so sub-4KB requests incur full 4KB I/O padded with zeros, while larger reads require additional requests per file. As Linux headers reside in the first 128 bytes, evaluation results show 4KB suffices for most malicious files.

Reading the first 4KB enables header sampling to excel against executable malware requiring loader compatibility (ELF/PE). Packed binaries, ransomware, and rootkits must alter headers for unpackers or encrypted payloads, unlike data files hiding payloads at arbitrary offsets. This 4KB page-aligned approach reduces per-file I/O independent of file size while retaining binary format anomaly sensitivity, providing high-frequency first-line defense.


\subsection{Hash-Based Spatial Mapping}
\label{design_3}

\noindent\textbf{Spatial Invariance.} After asynchronously reading metadata and 4KB header blocks, \DeepVis must transform thousands of unordered files into a fixed-size tensor for neural processing. Traditional ordering-based approaches (e.g., alphabetical sorting by path or directory tree) suffer from the Ordering Problem. Inserting a single new file shifts the indices of all subsequent files, destroying spatial locality across scans and invalidating trained neural network models. To overcome this, \DeepVis employs a deterministic hash-based spatial mapping to project each file onto a fixed-size grid.



\begin{figure}[t]
    \centering
    \includegraphics[width=9cm]{Figures/Design/Hash_Arch.pdf}
    \caption{Shift invariance comparison. Top: Traditional ordered approach creates catastrophic global index shifts when File D inserts between B and C. Bottom: Hash-based mapping ensures local stability—only affected pixels change positions independently.}
    \label{fig:hash}
\end{figure}

Figure~\ref{fig:hash} illustrates the comparison between the traditional ordered approach and the hash-based mapping employed by \DeepVis. As depicted in the upper panel, inserting File B forces updates to the indices of files C and D. This cascading shift becomes critically expensive in large-scale cloud systems containing millions of files. In contrast, the lower panel demonstrates how \DeepVis calculates stable coordinates $\Phi(p)$ for each file path $p$. By utilizing a high-entropy secret key $K$ generated at startup, the system maps files onto a fixed-size $128 \times 128$ tensor. This process generates a uniform representation of the file system state and facilitates the visualization of system health.

To derive coordinates for each file, \DeepVis employs the first 32 bits of the HMAC output modulo 128 for the x-coordinate and the subsequent 32 bits (bits 32 to 64) modulo 128 for the y-coordinate. The utilization of HMAC to establish stable coordinates provides two critical benefits. First, deterministic bucket mapping ensures that coordinates depend solely on the file path and the secret key, producing reproducible $128 \times 128$ grids across successive scans. Second, cryptographic key $K$ defeats targeted mapping attacks. Adversaries cannot craft filenames to reach specific low-risk coordinates. Ephemeral keys and privileged memory access restrict $K$ extraction.

\noindent\textbf{Multi-Modal RGB Encoding} Within the hash-mapped coordinate space, \DeepVis encodes each pixel through three risk channels: Red, Green, and Blue. These represent file characteristics for image-based visualization. The channels leverage malware feature orthogonality, ensuring evasion of one channel increases risk in others.

\begin{itemize}[leftmargin=*]
    \item \textbf{R (Entropy)} The Shannon entropy of the 4KB file header exploits the inherent trade-off in malware design. Legitimate ELF binaries incorporate zero-padding for section alignment, resulting in low entropy, whereas packed malware employs high information density to obfuscate signatures. This channel effectively distinguishes packed threats from standard system executables.

\item \textbf{G (Context Hazard)} To mitigate false positives from benign high-entropy files such as PNG images, environmental context receives quantification through a weighted sum:
\begin{equation}
    G = \min(1.0, P_{path} + P_{hidden} + P_{depth} + P_{size} + P_{perm})
\end{equation}
This path-sensitive metric evaluates files based on both content and location. A high-entropy file appears benign in \texttt{/usr/share} but suspicious in \texttt{/tmp}, with elevated weights assigned to hidden files and deep nesting as indicators of payload drops.

\item \textbf{B (Structure)} Structural anomalies emerge through raw ELF header parsing. This channel counters masquerading by assigning elevated risk scores to relocatable objects outside build directories and files exhibiting extension mismatches.
\end{itemize}

This RGB encoding transforms the abstract file system state into a dense numerical tensor $T \in \mathbb{R}^{128 \times 128 \times 3}$. This transformation enables the downstream Hash-Grid Parallel CAE to learn complex cross-channel correlations. The scanner maintains an inverted index that maps each pixel coordinate back to its constituent file paths. This ensures that operators can attribute the violation to a specific file once an anomaly is detected.

\noindent\textbf{Mapping Robustness and Security} ince the grid size remains fixed while cloud systems scale to massive file counts, hash collisions become inevitable. Existing anomaly detection models, such as Set-based Autoencoders (Set-AE), rely on global pooling (e.g., averaging), which suffers from signal dilution. 
However, detecting a specific adversarial signal from a single malicious file is critical in file system monitoring.


\DeepVis addresses both natural hash collisions and adversarial targeting through a unified robustness strategy. First, to manage inevitable collisions in the fixed $128 \times 128$ grid, \DeepVis employs maximum risk pooling, which constructs the pixel tensor by retaining the maximum feature value across all colliding files for each RGB channel. Thus, a single high-risk file determines each pixel value, ensuring malicious signals dominate despite benign collisions.
Second, to prevent bucket targeting attacks where adversaries craft filenames to collide with specific coordinates, the system utilizes a high-entropy secret key $K$. Periodic rotation of $K$ shuffles the entire grid without requiring model retraining, as the downstream $1 \times 1$ convolutional processing operates independently of spatial coordinates.



\subsection{Hash-Grid Parallel CAE}
\label{design_4}

\begin{figure}[t]
    \centering
    \includegraphics[width=9cm]{Figures/Design/CNN_Arch.pdf}
    \caption{Set-AE vs. Hash-Grid CAE. Top: Set-AE global pooling dilutes single malicious signal among benign files (Spike Lost). Bottom: Hash-Grid CAE processes 16K pixels independently; $L_\infty$ pooling captures isolated spikes.}
    \label{fig:comparison}
\end{figure}

\noindent\textbf{The Signal Dilution Problem at Scale.} A fundamental limitation of Set-based Autoencoders (Set-AE) in hyperscale storage is the reliance on global pooling strategies. As the number of monitored files increases, the feature vector of a single compromised file is aggregated with an increasing volume of benign metadata. This results in \textit{Signal Dilution}, where the anomaly score of a stealthy rootkit falls below the global variance threshold. Figure~\ref{fig:comparison} (top) demonstrates that this architectural flaw makes Set-AE unsuitable for large-scale cloud systems where $N_{benign} \gg N_{malicious}$.

\noindent\textbf{Parallel Pixel-Wise Processing.} To achieve scalability, \DeepVis adopts a $1 \times 1$ Convolutional Autoencoder architecture that operates on the fixed-size tensor grid (16,384 pixels). Unlike standard CNNs that extract spatial shapes, this model utilizes four point-wise layers (Enc: $3 \to 16 \to 8$, Dec: $8 \to 16 \to 3$) to learn cross-channel correlations independently for each pixel:
\begin{equation}
    T'_{x,y} = \sigma(W_{dec} \cdot \text{ReLU}(W_{enc} \cdot T_{x,y}))
\end{equation}
This design ensures that the reconstruction of a potentially malicious pixel depends solely on its own RGB features, effectively decoupling the model's sensitivity from the total file count. Consequently, DeepVis maintains constant inference latency ($O(1)$), enabling consistent performance across diverse instance sizes.

\noindent\textbf{Solving the MSE Paradox in Active Clouds.} Production environments are characterized by frequent legitimate updates (e.g., package upgrades), which introduce "diffuse noise" (high global error). Global MSE metrics often misclassify this benign churn as anomalous. \DeepVis resolves this via Maximum Deviation ($L_\infty$) scoring:
\begin{equation}
    Score = \max_{i,j} |T_{i,j} - T'_{i,j}|
\end{equation}
By focusing on the single maximum pixel deviation rather than the average error, the system effectively separates the sparse, high-magnitude signal of an attack from the diffuse, low-magnitude noise of system updates (Figure~\ref{fig:comparison}, bottom). This property is essential for minimizing false positives in dynamic DevOps workflows.

\noindent\textbf{Unsupervised Calibration.} The CAE is trained on benign-only baselines to model legitimate system states. The detection threshold $\tau$ is calibrated to the maximum $L_\infty$ loss observed in the validation set, ensuring strict zero-false-positive operation.


\subsection{\DeepVis Implementation}

We implemented \DeepVis using a hybrid Rust-Python architecture that combines high-performance I/O with machine learning capabilities. The Rust \texttt{deepvis\_scanner} module handles asynchronous 4KB header reads via \texttt{io\_uring} (512-deep queues) and parallel path collection via \texttt{rayon}, computing Shannon entropy on 4KB headers, generating HMAC-based hash coordinates for 128$\times$128 tensor mapping, and applying max-risk pooling into 3$\times$128$\times$128 float tensors. Python bindings via \texttt{pyo3} expose the \texttt{DeepVisScanner} class with \texttt{scan()}, \texttt{scan\_to\_tensor()}, and \texttt{scan\_to\_csv()} methods, where \texttt{ScanResult} provides detailed timing and files-per-second throughput for direct PyTorch inference or ONNX export on CPU-only edge devices. Key optimizations follow the hybrid pipeline design with CPU-bound path traversal filling pending queues faster than I/O consumption, kernel handling 4KB data movement while user-space processes entropy and RGB encoding, and exclusion of volatile directories (proc, sys, dev, run).
