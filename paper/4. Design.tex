\section{Design}~\label{Design}

In this section, we present \DeepVis, a hierarchical anomaly detection framework that transforms file system integrity monitoring into a computer vision problem. Drawing inspiration from multi-level intrusion detection systems~\cite{unicorn, cheng2024kairos}, \DeepVis employs a \textbf{Detection Funnel} architecture that maximizes efficiency while maintaining detection accuracy.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{Figures/DeepVis_Overall.png}
    \vspace{-0.6cm}
    \caption{\textbf{DeepVis Detection Pipeline.} Files are collected and mapped to fixed-size RGB images via Hash-Based Spatial Mapping. The hierarchical funnel applies: (1) Baseline Comparison for fast rejection, (2) Entropy Analysis for semantic filtering, and (3) Local Difference Map for precise localization. This pipelining ensures $O(1)$ inference complexity regardless of file count.}
    \label{fig:deepvis_overall}
    \vspace{-0.4cm}
\end{figure*}

\subsection{The Detection Funnel: Hierarchical Pipeline}

\DeepVis processes file system states through a three-stage hierarchical pipeline, enabling \textbf{early rejection} of benign states while focusing computational resources on suspicious regions.

\subsubsection{Stage 1: Baseline Comparison (Coarse Filter)}

The first stage performs a fast set-difference operation between the current state $S_{current}$ and the baseline $S_{baseline}$:
\begin{equation}
    \Delta_{new} = \{f \in S_{current} : f.path \notin S_{baseline}\}
\end{equation}

If $|\Delta_{new}| = 0$ (no new files), the system skips expensive analysis and returns immediately. This handles the common case where legitimate updates only \textit{modify} existing files without adding new ones.

\noindent\textit{Rationale:} Similar to ScaleMon's Identity Verifier~\cite{scalemon}, this stage provides \textbf{fast rejection} for the majority of benign states, addressing Alert Fatigue at minimal computational cost.

\subsubsection{Stage 2: Entropy-Centric Semantic Analysis}

For states with new files, Stage 2 applies entropy-based filtering:
\begin{equation}
    \Delta_{suspicious} = \{f \in \Delta_{new} : S(f) > \tau_{entropy} \land f.path \in \mathcal{P}_{critical}\}
\end{equation}
where $\tau_{entropy} = 7.0$ (packed/encrypted threshold) and $\mathcal{P}_{critical}$ includes security-sensitive paths (\texttt{/lib/modules/}, \texttt{/usr/bin/}, etc.).

This stage filters out benign new files (e.g., log rotations, config updates) that have normal entropy ($S < 6.5$).

\subsubsection{Stage 3: Local Difference Map (Fine-Grained Localization)}

For states flagged by Stage 2, we generate the full visual representation and compute pixel-wise reconstruction error via the CAE:
\begin{equation}
    D = |X - \hat{X}|, \quad LocalMax = \max_{x,y,c} D_{x,y,c}
\end{equation}

The Local Difference Map provides:
\begin{itemize}
    \item \textbf{Detection:} $LocalMax > \tau$ triggers an alert
    \item \textbf{Localization:} Coordinates $(x^*, y^*)$ identify the anomalous file(s)
    \item \textbf{Explanation:} Channel color indicates anomaly type (R=Entropy, G=Size, B=Permissions)
\end{itemize}

\subsection{Hash-Based Spatial Mapping}
\label{sec:hash_mapping}

To resolve the non-Euclidean nature of file systems, we formalize our mapping strategy as follows.

\subsubsection{Formal Definition}

Let $\mathcal{F} = \{f_1, \dots, f_N\}$ be a set of files, where each file $f_i$ is uniquely identified by its absolute path $p_i \in \mathcal{P}$. We define a spatial mapping function $\Phi: \mathcal{P} \to [0, W-1] \times [0, H-1]$:

\begin{equation}
    \Phi(p) = \left( \mathcal{H}(p) \pmod W, \left\lfloor \frac{\mathcal{H}(p)}{W} \right\rfloor \pmod H \right)
\end{equation}
where $\mathcal{H}: \{0,1\}^* \to \{0,1\}^{32}$ is a cryptographic hash function (e.g., MD5 truncated).

\subsubsection{Theoretical Properties}

\noindent\textbf{Theorem 1 (Spatial Invariance).} The image representation $I_\mathcal{F}$ generated by $\Phi$ is invariant to the ordering of files in $\mathcal{F}$. That is, for any permutation $\pi$ of indices $\{1, \dots, N\}$:
\begin{equation}
    I_{\{f_1, \dots, f_N\}} = I_{\{f_{\pi(1)}, \dots, f_{\pi(N)}\}}
\end{equation}

\noindent\textit{Proof.} The pixel value at coordinate $(x,y)$ is determined solely by the subset of files $\{f \in \mathcal{F} \mid \Phi(f.path) = (x,y)\}$. Since set membership is order-independent, the resulting pixel aggregation (via Max-Risk Pooling) is deterministic and independent of the input sequence. Thus, \DeepVis completely eliminates the Shift Problem observed in sorting-based approaches, ensuring that a file added at time $t$ always maps to the same coordinate at time $t+1$. $\square$

\subsubsection{Collision Handling: Max-Risk Pooling}

When multiple files map to the same pixel, we apply:
\begin{equation}
    I_{x,y}^c = \max_{f \in bin(x,y)} \left( Feature_c(f) \right)
\end{equation}

\noindent\textit{Security Rationale:} In security, surfacing the highest-risk signal prevents false negatives.

\subsection{Semantic RGB Encoding}

We construct a 3-channel tensor $T \in \mathbb{R}^{3 \times H \times W}$ where each channel encodes a security-relevant feature aligned with the CIA triad:

\begin{table}[t]
\centering
\caption{Threat Mapping: Security Goals to Visual Footprint}
\label{tab:threat_mapping}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{llll}
\toprule
\textbf{Security Goal} & \textbf{Rootkit Technique} & \textbf{FS Artifact} & \textbf{RGB Channel} \\
\midrule
\multirow{2}{*}{Confidentiality} & Data Exfiltration & Hidden file & Red (Entropy) \\
& Keylogger & New binary & Red + Blue \\
\midrule
\multirow{2}{*}{Integrity} & Binary Replacement & Size change & Green (Size) \\
& LKM Injection & High entropy & Red (Entropy) \\
\midrule
\multirow{2}{*}{Availability} & Permission Backdoor & SUID/SGID & Blue (Perms) \\
& Resource Hijack & Size anomaly & Green (Size) \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Channel Definitions (DeepVis 2.0 Enhanced)}

Building on the original three-channel design, \textbf{DeepVis 2.0} introduces enhanced semantic encoding to defeat evasion attacks:

\noindent\textbf{Red Channel (Entropy):} Shannon entropy normalized to $[0, 1]$:
\begin{equation}
    I^{Red} = \min\left( \frac{S(f)}{8.0}, 1.0 \right)
\end{equation}
Packed/encrypted rootkits exhibit $S > 7.0$, appearing as bright red pixels.

\noindent\textbf{Green Channel (Size + API Density):} Log-normalized file size combined with API density:
\begin{equation}
    I^{Green} = \max\left( \frac{\log(1 + Size(f))}{\log(MaxSize)}, \frac{API(f)}{0.5} \right)
\end{equation}
where $API(f)$ measures density of suspicious function calls (ptrace, socket, execve, dlopen). This enhancement detects \textit{low-entropy scripts} with malicious functionality.

\noindent\textbf{Blue Channel (Permissions + Time Anomaly):} Risk-weighted score:
\begin{equation}
    I^{Blue} = 0.6 \cdot Perm(f) + 0.4 \cdot TimeAnomaly(f)
\end{equation}
where $TimeAnomaly(f)$ detects timestomping (mtime $<$ ctime).

\subsubsection{Multi-Signal Detection (DeepVis 2.0)}

To address sophisticated evasion attacks, DeepVis 2.0 employs \textbf{multi-signal detection}:

\begin{table}[t]
\centering
\caption{DeepVis 2.0: Multi-Signal Detection}
\label{tab:multi_signal}
\begin{tabular}{lcc}
\toprule
\textbf{Signal} & \textbf{Threshold} & \textbf{Targets} \\
\midrule
Entropy (NEW file) & $S > 7.0$ & Packed rootkits \\
API Density (NEW) & $API > 0.4$ & Malicious scripts \\
Size Change (existing) & $\Delta > 3\%$ & PARASITIC injection \\
Time Anomaly (NEW) & $score > 0.5$ & Timestomping \\
\bottomrule
\end{tabular}
\end{table}

This multi-signal approach addresses the limitations of entropy-only detection, achieving 100\% detection on PARASITIC, MIMICRY, and TIMESTOMP attacks that evade DeepVis 1.0.

Table~\ref{tab:threat_mapping} demonstrates that RGB channels are not arbitrary but \textbf{semantically aligned with security violations}.

\subsection{Scalability Analysis: The $O(1)$ Inference Advantage}

A critical contribution of \DeepVis is \textbf{decoupling analysis complexity from file count}.

\subsubsection{Traditional FIM: $O(N)$ Scaling}

AIDE and similar tools iterate over all $N$ monitored files:
\begin{equation}
    T_{AIDE} = O(N) \cdot c_{hash}
\end{equation}
For hyperscale file systems ($N > 10^6$), this becomes prohibitive.

\subsubsection{DeepVis: $O(1)$ Fixed-Tensor Inference}

Regardless of $N$, \DeepVis maps files to a fixed $W \times H$ tensor (default: $128 \times 128 = 16,384$ pixels):
\begin{equation}
    T_{DeepVis} = O(N) \cdot c_{map} + O(1) \cdot c_{CNN}
\end{equation}

The mapping cost $c_{map}$ is negligible (hash + array access). The CNN inference $c_{CNN}$ is \textbf{constant} regardless of $N$:

\begin{table}[t]
\centering
\caption{Scalability: File Count vs. Inference Time}
\label{tab:scalability}
\begin{tabular}{lcc}
\toprule
\textbf{File Count} & \textbf{AIDE} & \textbf{DeepVis} \\
\midrule
1,000 & 0.3s & 0.05s \\
10,000 & 3.1s & 0.08s \\
100,000 & 31.2s & 0.12s \\
1,000,000 & 312s & 0.15s \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textit{Implication:} \DeepVis is the only viable solution for \textbf{hyperscale file systems} with millions of files.

\subsection{Neural Architecture}

\DeepVis employs a lightweight Convolutional Autoencoder (CAE):

\noindent\textbf{Encoder:} Conv2D(3→32→64→128) with stride-2 downsampling.\\
\noindent\textbf{Decoder:} ConvTranspose2D(128→64→32→3) with stride-2 upsampling.\\
\noindent\textbf{Latent:} $z \in \mathbb{R}^{128 \times 16 \times 16}$

The CAE is trained \textit{only} on baseline states, learning the manifold of ``normal'' configurations. Rootkit-infected states, being out-of-distribution, exhibit localized reconstruction error.
