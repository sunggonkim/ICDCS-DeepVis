

\section{Design}~\label{Design}
In this section, we present \ScaleMon, \taebin{blarr blarr}

% scalable system and application monitoring scheme and attack detection using the monitored information.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{Figures/ScaleMon_Overall.png}
    \vspace{-0.6cm}
    \caption{Overall Architecture\taebin{draft}}
    \label{ScaleMon_overall}
    \vspace{-0.6cm}
\end{figure*}




\subsection{Overall Architecture}
\ScaleMon is a novel, lightweight, and scalable hierarchical IDS for HPC systems. Its detection pipeline is composed of two data processing stages—a LogParser and a FingerprintGenerator—and three specialized detection modules: the \IdentityVerifier, \InterMon, and \IntraMon. Each module is designed to focus on different scales and aspects of I/O behavior to provide comprehensive threat coverage. Figure~\ref{ScaleMon_overall} illustrates the overall architecture and data flow of \ScaleMon's detection pipeline.

The pipeline begins post-execution by scrutinizing the generated Darshan logs. The LogParser first converts the binary \texttt{.darshan} file into two intermediate text files, \texttt{darshan.txt} and \texttt{dxt.txt}, using Darshan's utility tools. During this phase, the application's Claimed Identity is extracted from the binary name found in \texttt{darshan.txt}. These text files are then parsed into two structured tables: a \texttt{summary.csv} and a \texttt{detailed.csv}. The \texttt{summary.csv} provides a comprehensive, execution-level overview of all accessed files and serves as the basis for inter-file analysis. The \texttt{detailed.csv}, conversely, contains the fine-grained I/O traces for files accessed via specific interfaces like \texttt{POSIX I/O}. Finally, the Fingerprint Generator processes these tables, aggregating and transforming the summary.csv into Execution Profile Vectors and the \texttt{detailed.csv} into I/O Images for the subsequent detection stages.

The detection pipeline then commences with the \IdentityVerifier, which compares the Claimed Identity with an Inferred Identity predicted from the I/O image. If they do not match, an alert for a potential masquerading attempt is raised, and further analysis is bypassed. If the identity is verified, the execution proceeds to the in-depth inspection stages, which operate in parallel. Specifically, \InterMon analyzes the Execution Profile Vectors to detect anomalies at the inter-file level, capturing the macroscopic behavior and context of file accesses. Concurrently, \IntraMon scrutinizes the I/O Images to identify suspicious patterns at the fine-grained, intra-file level. An alarm is triggered if an anomaly is detected by either module, leveraging their complementary perspectives to provide comprehensive detection.

% \subsection{Fingerprint Generator}
% Finger print Generator represent table data to ...
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{Figures/Fingerprint_Generator.jpg}
%     \vspace{-0.6cm}
%     \caption{Data Representations}
%     \label{Fingerprint_Generator}
%     \vspace{-.6cm}
% \end{figure}

\subsection{Fingerprint Generator}
Finger print Generator represent table data to ...

\subsubsection{Execution Profiles Vector: Inter-file Level Fingerprint}

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{Figures/Execution_Profile_Vector.png}
    \vspace{-0.6cm}
    \caption{Execution Profile Vector}
    \label{Execution_Profile_Vector}
    \vspace{-.6cm}
\end{figure}

To comprehensively summarize the inter-file level I/O behavior, we generate two complementary vectors for each execution: the \textbf{Job Profile Vector} and the \textbf{File Profile Vectors}. Specifically, a single Job Profile Vector represents the execution globally, while a File Profile Vector is generated for each file accessed during the execution. These vectors treat files as atomic objects, capturing both the specific characteristics of individual file accesses within the context of other accessed files and the aggregate behavior of the entire job. Figure~\ref{Execution_Profile_Vector} visualizes the composition of these vectors.

\noindent\textbf{File Profile Vector}
The File Profile Vector creates a unique fingerprint for each accessed file by addressing three fundamental contextual questions: \textit{what} type of file it is, \textit{how} it is operated, and \textit{where} it is located relative to others. By concatenating the sub-vectors corresponding to these questions, we form a unified representation for every file involved in the execution.

\textbf{What: File Type.} This component identifies the semantic category of the file based on its name or extension. Specifically, a predefined keyword dictionary is utilized to classify the file. If a direct match is not found, the last token of the base name serves as a fallback feature. During the training phase, all unique file types are mapped to positions in a one-hot encoded vector. In the inference phase, any unseen file types result in a zero-vector. In the \textit{\InterMon} module, such unknown types are flagged for immediate inspection before passing through the ML model, as accessing unusual file types is inherently suspicious in HPC applications.

\textbf{How: Operation Type.} This component describes the nature of the I/O operations performed on the file. It is represented as a 2-bit vector, where the first bit indicates a 'Read' operation and the second indicates a 'Write' operation. For instance, a file that is both read from and written to during an execution is encoded as \texttt{[1, 1]}, whereas a read-only file is \texttt{[1, 0]}.
By analyzing 'What' and 'How' jointly, we can detect semantic anomalies, such as illegitimate write operations to typically read-only configuration files. However, these two dimensions alone cannot detect attacks involving legitimate operations on anomalous file paths, which can still pose a severe threat to confidentiality. To address this, a spatial component representing the file location is required.

\textbf{Where: Relational Location.} This component quantifies the spatial relationship of a specific file within the directory structure relative to other files accessed in the same execution. We quantify this "spatial distance" using the Lowest Common Ancestor (LCA) in the directory tree. Formally, the distance function $d(\text{file}_1, \text{file}_2)$ is defined as:
\begin{equation}
d(\text{file}_1, \text{file}_2) = d(\text{file}_1, \mathrm{LCA}) + d(\text{file}_2, \mathrm{LCA})
\end{equation}
where $\mathrm{LCA}$ denotes the lowest common ancestor directory of $\text{file}_1$ and $\text{file}_2$.

\noindent We define the base cases as:
\begin{align}
d(x, x) &= 0, \\
d(\text{parent}, \text{child}) &= 1.
\end{align} 
For each accessed file, we compute three statistical features based on its pairwise LCA distances to all other accessed files: the \textit{min}, \textit{mean}, and \textit{max} distance. Using these components, a file located in a distant path relative to others will exhibit prominent distance values, effectively flagging it as a spatial outlier.

\noindent\textbf{Job Profile Vector}
While the File Profile Vector characterizes individual files, relying solely on it has limitations. An attack might consist of operations that appear benign at the file level—such as legitimate operations on valid file types—but are malicious at the job level, for instance, accessing an excessive number of files to induce a Denial of Service. Therefore, the Job Profile Vector is necessary to comprehensively represent the macroscopic inter-file level I/O behavior.

This vector aggregates statistics to answer three macroscopic questions: \textit{how many} files were accessed per type, \textit{how scattered} the accesses were across the file system, and \textit{how long} the execution persisted. First, to capture the volume of activity (\textbf{how many}), we accumulate the one-hot encoded file type vectors from all File Profiles, resulting in a distribution vector that counts the occurrences of each file type. Second, to measure the spatial dispersion of I/O (\textbf{how scattered}), we compute the global minimum, mean, and maximum LCA distances between all pairs of files accessed during the execution. Finally, we record the total runtime (\textbf{how long}) to provide temporal context relative to the I/O behavior. By combining these macroscopic features, the Job Profile Vector effectively complements the microscopic details of the File Profile Vector.

\subsubsection{The I/O Image: Intra-file level Fingerprint}

\begin{figure}[t]
    \centering
    \includegraphics[width=8.5cm]{Figures/IO_Image.png}
    \vspace{-0.6cm}
    \caption{I/O Image}
    \label{IO_Image}
    \vspace{-.6cm}
\end{figure}

At the core of our microscopic analysis lies the I/O Image, a novel representation designed to transform voluminous, fine-grained I/O logs into a compact and analyzable format. For each execution, we selectively generate I/O Images only from the files recorded in the DXT logs\taebin{dxt.txt?}, which provide detailed traces of POSIX I/O operations. The complete log of I/O activities for a single file is converted into one fixed-size I/O image tensor with dimensions of $2 \times \texttt{image\_size} \times \texttt{image\_size}$, where \texttt{image\_size} is a configurable hyperparameter.

\taebin{references should be added to enforce our argument
difficulty of }
The motivation for this transformation is twofold, enhancing both efficiency and effectiveness. From an efficiency standpoint, raw DXT logs can be excessively large, often reaching gigabytes in seconds\taebin{should be measured}, making direct analysis computationally prohibitive in terms of both time and memory. Our fixed-size image representation drastically compresses this data, enabling lightweight and scalable processing. More importantly, this transformation is often more effective than analyzing the raw time-series data directly. Due to the extreme length of I/O sequences, \taebin{too deterministic?}any time-series analysis must operate on small, windowed segments of the data. This window-level inspection inherently struggles to capture the global, long-range patterns of an execution, focusing only on local behaviors. In contrast, our I/O image normalizes the entire execution's I/O activity for a file into a single, holistic view, allowing our models to capture both local and global patterns simultaneously. efficiency and effectiveness of this representation is evaluated on Section ~\ref{Superiority_of_I_O_Image}


Figure~\ref{IO_Image} visualizes the process of converting the spatio-temporal I/O patterns of a file into an I/O image. The three dimensions of the image tensor are mapped as follows:

\noindent\textbf{Channel (Axis 0):} The two channels distinguish the I/O operation type, with channel 0 representing read operations and channel 1 for write operations.

\noindent\textbf{Height (Axis 1):} The vertical position of a pixel corresponds to the I/O offset, which is normalized via min-max scaling to fit the image height.

\noindent\textbf{Width (Axis 2):} The horizontal position corresponds to the I/O time, which is also normalized to fit the image width.

\noindent The pixel value at a specific \texttt{(channel, height, width)} coordinate is the accumulated sum of the sizes of all I/O accesses that fall into that spatio-temporal bin. Finally, the pixel values within each channel are normalized to a range of \texttt{[0, 1]}. Through this process, the entire sequence of spatio-temporal access patterns from the DXT log is encoded into a single, dense I/O image.

\taebin{all component process data as batch but it mentioned only in some section.}

\subsection{\IdentityVerifier}
The \IdentityVerifier serves a dual purpose within the \ScaleMon architecture: ensuring routing integrity and providing early-stage anomaly detection. Primarily, its role is to validate the consistency between an application's claimed identity (e.g., binary filename) and its actual I/O behavior. This step is critical because the subsequent modules, \InterMon and \IntraMon, are designed to monitor adherence to specific application profiles. If an execution stream is routed to an incorrect model due to a deceptive identity, the system could be misled, resulting in unreliable detection. Simultaneously, this module functions as an initial gatekeeper. By inspecting the intra-file level I/O behavior via I/O Images, it detects less stealthy attacks that exhibit patterns distinctively different from the claimed application's benign behavior. Identifying such overt anomalies at this stage allows \ScaleMon to flag the execution immediately, bypassing both subsequent monitoring phases, \InterMon and \IntraMon.

To implement this, we employ a lightweight CNN-based classifier (ResNet18) trained on benign I/O Images to distinguish between application types. This training can be performed offline using historical benign I/O Images accumulated by running \ScaleMon. During detection, the module processes all I/O Images generated from an execution in a batch. For each image, it evaluates the classifier's confidence score for the claimed identity. If the confidence falls below a predefined threshold (0.6 in this work), it implies that the observed behavior does not align with the claim. If any single image in the batch is flagged as suspicious, the entire execution is treated as a potential masquerading attempt or anomaly, triggering an immediate alert.



\subsection{\InterMon}
The \InterMon module is responsible for scrutinizing the inter-file level behavior captured in the Execution Profile Vectors. It operates by evaluating the Job Profile Vector and the set of File Profile Vectors in parallel, using distinct models for each vector type. The system triggers an alert if any individual vector is flagged as anomalous. This parallel processing ensures that inter-file level deviations are captured simultaneously across different granularities.

To ensure robustness against zero-day attacks and independence from specific attack signatures, we employ one-class anomaly detection models. These models are trained exclusively on benign execution data, enabling them to identify any deviation from normal patterns as suspicious. Specifically, each model outputs an anomaly score for the input vector; if this score exceeds a predefined threshold, the execution is judged as an anomaly. In this work, the threshold is set at the 99th percentile of the anomaly scores observed in the benign training data, and this threshold can be adaptively updated during operation. The architecture is model-agnostic, supporting algorithms such as k-NN, LOF, Isolation Forest, and AutoEncoders, as evaluated in Section~\ref{component_wise_detection_performance}. Among these, we primarily adopt the Deep SVDD model for our evaluation due to its efficiency and performance.

\subsection{\IntraMon}
The \IntraMon module performs an intra-file level inspection of the I/O Images that have successfully passed the \IdentityVerifier. Its primary objective is to detect highly stealthy attacks that appear benign at the inter-file level and exhibit patterns deceptively similar to normal operations at the intra-file level. For efficient processing, all I/O Images associated with a single execution are evaluated in a batch. if any individual image within the batch is flagged as anomalous, the entire execution is immediately alerted as suspicious.

The detection process begins by capturing the graphical patterns of the I/O Image using a CNN embedder. We utilize a CNN pre-trained on the ImageNet dataset as a fixed, train-free feature extractor. The role of this embedder is to capture semantic graphical patterns and distill them into a compact one-dimensional vector of size \textit{embed\_dim}, which serves as the input for the anomaly detection model. The choice of the backbone model and the embedding dimension are configurable hyperparameters; in this work, we employ ResNet18 as the backbone and set the embedding dimension to 256. We evaluate the impact of these choices and select the optimal configuration in Section~\ref{component_wise_detection_performance}. Following feature extraction, one-class anomaly detection is conducted using the same methodology as \InterMon. As demonstrated in Section~\ref{component_wise_detection_performance}, this approach exhibits model-agnostic robustness, highlighting the superiority of our feature representation. Consistent with \InterMon, we primarily adopt the Deep SVDD model for evaluation in this work due to its efficiency and performance.

% \subsection{adaptation}

% \subsection{Behavioral Fingerprinting via I/O Image Representation}
% I/O log is big. unpractical or even unfeasible to handle in row format. so need compression, retaining critical information to ...,


% % To effectively capture an application's intrinsic behavior, we introduce a novel data representation we term the "I/O Image." Raw, time-series I/O logs, while detailed, are often voluminous and computationally expensive to analyze directly. Our approach addresses this by transforming the I/O access patterns within a file into a fixed-size, information-rich 2D image tensor. This I/O image serves as a powerful behavioral fingerprint, encoding the fundamental spatio-temporal dynamics of how an application interacts with its data.

% % A critical design choice is to generate I/O images selectively, targeting only the most I/O-intensive and behaviorally significant files rather than every file accessed during an execution. Analyzing all files, including small configuration or log files with sparse I/O, would not only incur significant computational overhead but also increase the likelihood of false positives due to their inherently noisy and less structured access patterns. By focusing on the primary data files where an application's core algorithms are reflected, we maximize the signal-to-noise ratio, enabling more precise and efficient anomaly detection.

% % The selection of target files is guided by domain knowledge of common HPC applications and their primary data formats. These are typically large, structured files where the majority of scientific computation's I/O occurs. For instance, in our work, we target well-known formats prevalent in leading scientific codes:
% % HDF5 (.h5, .hdf5): A ubiquitous format for structured, hierarchical data used across numerous domains, including in applications like VPIC for plasma physics simulations and many deep learning frameworks.
% % VASP (Vienna Ab initio Simulation Package): For electronic structure calculations, we target core output files such as CHGCAR (charge density) and WAVECAR (wavefunctions), which exhibit highly regular, grid-based access patterns.
% % GROMACS: In molecular dynamics simulations, the primary trajectory files (.xtc, .trr) that store particle coordinates over time are ideal subjects for I/O image analysis.
% % Gaussian: For quantum chemistry computations, checkpoint files (.chk) and formatted checkpoint files (.fchk), which store the entire state of a calculation, are key targets.
% % By predefining a whitelist of such critical file formats for each application class, our framework can robustly capture the most meaningful behavioral fingerprints.
% % (but not tested)

% \subsection{Identity-Behavior Verifier}
% This module is introduced To see if the claimed identity matches the actual behavior. using Image formet as a fingerprint.

% \subsection{Execution Profile Analyzer}
% Many general attack will leave trace on Macroscopic I/O log, persueing their own malicious goal. so this module is needded
% \subsubsection{File-level Contextual Profile}
% represent: What, How, Where

% \textbf\noindent{Anomaly Detection using Auto Encoder (can be changed)}

% \subsubsection{Execution-level Statistical Profile}

% File-level alone is not enough.
% represent: What(accumulated one-hot vector), where(histogram), How long(run time)

% \subsection{Microscopic I/O Inspector}

% \textbf\noindent{feature extraction}
% In order to extract information in images in comprehensive and detailed ways, CNN feature extractor is used.
% global average pooling

% \textbf\noindent{Anomaly Detection using GMM? (can be changed)}



% \textbf{Image}
% This image represent the Microscopic I/O pattern in intra-file level. Access log to big intensive file or files in each excution which contains rich information about application's behavior become subject of this image generation. target of this is predefined and we propose .h5, ?, ? ... as subject. because each execution with different I/O pattern show different Image it can used as fingerprint to identify them and further more to judge their legitimacy.

% this Image form is makde by ....

% \subsection{Identity-Behavior Verifier}
% This module is introduced To see if the claimed identity matches the actual behavior. using Image formet as a fingerprint. 

% \subsection{Execution Profile Analyzer}
% To Analyze whether the Profile of each execution is matched with expected profile of each excution. 
% \noindent\textbf{bird view}
% \noindent\textbf{insect view}

% \subsection{Microscopic I/O Inspector}
% Closely Inspect Micorscopic I/O pattern in intra-file scale. 
% \noindent\textbf{embedding}
% \noindent\textbf{anomaly detection}

% \subsection{adaptation to concept drift}

% Figure X illustrates the overall architecture of \ScaleMon. The Darshan I/O profiling tool monitors the execution’s I/O behavior and collects detailed information, including the binary file path, accessed files, and every I/O request made to each file. The collected data is initially stored in a binary \texttt{.darshan} format, which can be converted into a human-readable text file using darshan-dxt-parser, a component of the Darshan utility suite.

% In \ScaleMon, this readable file is further parsed into a tabular CSV format with the following columns: file\_path, rank, request\_type, request\_size, request\_offset, and request\_time. The resulting table is grouped by file, and from this structured data, two distinct representations are derived for each file: 

% \noindent\textbf{1.}  A one-dimensional feature vector representing the microscopic I/O behaviors. 

% \noindent\textbf\textbf{2.} An image capturing the microscopic I/O behavior within the file. 

% \noindent These two representations are independently analyzed by the Stage 1 and Stage 2 detectors, respectively. Through this two-stage design, \ScaleMon enables anomaly detection from both macroscopic  and microscopic  perspectives. 

% \taebin{if binary file name is tampered? this part need to be hardened}
% Prior to either detection stage, \ScaleMon identifies the running application by inspecting its binary file path and assigns the corresponding application-specific model for each stage. Although the main focus of \ScaleMon is to detect unfamiliar behaviors of familiar applications, it can also evaluate unseen applications that were not observed during the training phase. In such cases, a universal model, trained on the entire dataset, is allocated for the unseen binary. The feasibility of this approach is briefly discussed in Section 5.5.


% \subsection{Stage 1 detector}
% The Stage 1 detector is designed to perform a rapid, macroscopic analysis of each file access event by answering three fundamental contextual questions: What file is being accessed, How is it being accessed, and Where is it located in relation to other activities in the same execution. These three components are concatenated to form a one-dimensional feature vector for each accessed file, which is then evaluated by a lightweight autoencoder model.

% \textbf{1. What:} File Identity and Type. The 'What' dimension focuses on the identity and purpose of the accessed file, primarily inferred from its type. File type information is derived from the file extension or, in applications like VASP that use fixed filenames, from the filename itself. All file types observed during training are one-hot encoded, while any unseen file type is represented by a zero vector. This allows the model to flag anomalies such as an application attempting to access an unexpected or illegitimate file type (e.g., a shared library instead of a data file).

% \textbf{2. How:} Operation Type. The 'How' dimension captures the nature of the operation performed on the file. Each access is categorized into one of three types: read\_only, write\_only, or read\_and\_write. This component is crucial for detecting suspicious activities that violate expected behaviors, such as unexpected write operations on traditionally read\-only files like source code, executables, or input datasets.

% \textbf{3. Where:} Spatial Legitimacy. The 'Where' dimension evaluates the spatial legitimacy of a file access within the context of the entire execution. The underlying assumption is that legitimate file accesses during a single job execution should occur within a localized and related set of directories. We quantify this "spatial distance" between any two files using their Lowest Common Ancestor (LCA) in the directory tree. Formally, the distance function $d(\text{file}_1, \text{file}_2)$ is defined as:
% \begin{equation}
% d(\text{file}_1, \text{file}_2) = d(\text{file}_1, \mathrm{LCA}) + d(\text{file}_2, \mathrm{LCA})
% \end{equation}
% where $\mathrm{LCA}$ denotes the lowest common ancestor directory of $\text{file}_1$ and $\text{file}_2$.

% \noindent We define the base cases as:
% \begin{align}
% d(x, x) &= 0, \\
% d(\text{parent}, \text{child}) &= 1.
% \end{align}
% For each accessed file, we compute three statistical features from its pairwise LCA distances to all other accessed files: the F, mean, and farthest file distance. These metrics effectively characterize a file's contextual legitimacy and can identify outliers, such as a process suddenly accessing a file in a distant, unrelated directory, which might indicate data staging for exfiltration or access to a compromised file.

% These three components—What, How, and Where—are combined into a single feature vector that summarizes the macroscopic context of each file access. A pretrained autoencoder, trained exclusively on feature vectors from normal executions, then attempts to reconstruct this vector. Anomalous file accesses, deviating from learned normal patterns, result in high reconstruction errors. By applying a threshold to this error, each access is evaluated for abnormality. Owing to the model’s lightweight structure and the vector's simplicity, this inference process incurs negligible overhead and is fully parallelizable across all accessed files.

% % \subsection{Stage 1 detector}
% % \taebin{positioning with what, how, where will be better}
% % In Stage 1, the collected CSV logs are aggregated, and a one-dimensional feature vector is constructed for each accessed file. the vector is formed by concatenating three components: \textbf{(1)} a representation of the file type \textbf{(2)} a representation of the types of operations requested on the file, and \textbf{(3)} statistical features based on the Lowest Common Ancestor (LCA) distance that describes the structural relationship among accessed files.
% % The pretrained autoencoder then encodes and reconstructs each vector, measuring the deviation between the original and reconstructed representations. Since the model is trained exclusively on normal data and optimized for the reconstruction of such patterns, it can reconstruct normal samples more accurately, whereas anomalous ones yield larger reconstruction errors due to their deviation from the learned distribution. Each file access is thus evaluated by thresholding its reconstruction error to determine whether it is anomalous. Owing to the model’s lightweight structure, the inference incurs negligible overhead and can be fully parallelized across files.

% % File type information is mainly derived from the file extension, while in applications like VASP that use fixed filenames for specific purposes, the filename can also be used to infer the file type. All file types observed in the training data are encoded using a one-hot encoder, and any unseen file type during inference is represented by a zero vector. Subsequently, the type of operation requested on the file is represented using three positions, corresponding to \texttt{read\_only}, \texttt{write\_only}, and \texttt{read\_and\_write}. These two components provide superficial information about each file access, enabling the identification of malicious activities from a macroscopic perspective, such as unexpected write operations on source or script files.

% % The third component of the feature vector represents the relationships among files accessed during a given execution. Even a normally permitted operation, such as writing to an \texttt{h5} file, may become suspicious if the accessed file is located far apart from other files accessed in the same execution. distance between two files in a directory tree be defined based on their \textit{lowest common ancestor (LCA)}. 
% % Formally, the distance function $d(\text{file}_1, \text{file}_2)$ is defined as:
% % \begin{equation}
% % d(\text{file}_1, \text{file}_2) = d(\text{file}_1, \mathrm{LCA}) + d(\text{file}_2, \mathrm{LCA})
% % \end{equation}
% % where $\mathrm{LCA}$ denotes the lowest common ancestor directory of $\text{file}_1$ and $\text{file}_2$.

% % \noindent We define the base cases as:
% % \begin{align}
% % d(x, x) &= 0, \\
% % d(\text{parent}, \text{child}) &= 1.
% % \end{align}
% % For each accessed file, three statistical features are derived from the pairwise LCA distances: 
% % the closest file distance, the mean distance, and the farthest file distance. These metrics characterize the spatial legitimacy of a file access in the context of other files.

% \begin{table*}[!t]
% \footnotesize
% \centering
% \caption{Description of perturbation functions used in the SAG framework.}
% \label{tab:perturbation_functions}
% \begin{tabularx}{\textwidth}{l X}
% \toprule
% \textbf{Perturbation Function} & \textbf{Description} \\
% \midrule
% Add Instant Access & 
% simulates the effect of adding new access. The number of accesses to add is randomly selected from a predefined parameter space (in this work {1, 10, 100, 1000}). For each added access, the pixel value—representing the sum of request sizes allocated to each position is randomly sampled from a truncated normal distribution whose mean is defined as $k$ $\times$ the mean of non-zero pixel values in the original image, where $k$ is a hyperparameter set to 0.5 in this work. After adding these accesses (i.e., increasing the values of randomly selected pixels), the image is normalized using min–max scaling to ensure that all pixel values fall within 0 to 1\\

% \midrule
% Add Sequential Access & 
% Simulates the effect of adding sequential accesses. First, a range of lines is randomly selected, and then the insertion method—whether to add a new line and shift the existing ones backward, or to overlap the new accesses with the existing ones—is determined. Additional parameters, such as the number of chunks and the direction of access, are also randomly chosen to define the overall shape of the sequential pattern. The pixel values of the added sequential accesses are determined in the same manner as in the Add Instant Access function. After adding these accesses, the image is normalized  using min–max scaling. One line of sequential access is added per perturbation process.\\

% \midrule
% Change Request Size &
% Randomly modifies request sizes by altering the values of non-zero pixels. The number of pixels to modify is randomly selected from a predefined parameter space (in this work, 1, 10, 100, or 1000). For each selected pixel, the new value is obtained by multiplying the original value by a factor sampled from a predefined parameter space (in this work, {0.01, 0.1, 0.5, 1.5, 2.0, 3.0}). This perturbation introduces noise into request sizes.\\

% \midrule
% Insert Delay & 
% Introduces artificial latency between access requests to emulate temporary I/O stalls or processing delays. The number of delays to insert is randomly selected from a predefined parameter space (in this work, {1, 10, 100, 1000}). The start point and length of each delay are also randomly sampled from predefined parameter spaces, and whether all delays share the same length or have different lengths is defined as an additional parameter. This function does not modify pixel values, but only changes the timing of accesses.\\

% \midrule
% General data Augmentaion & 
% Applies common data augmentation techniques widely used for images~\cite{shorten2019survey}. The purpose is not to mimic attack patterns, but to increase the variability of the data. Specifically, rotation, flipping, and grid-based cut-mix are applied. The type of augmentation is randomly selected, and each is applied with parameters randomly sampled from predefined spaces. Rotation angles are selected from 90, 180, or 270 degrees; flipping can be horizontal or vertical; and for grid-based cut-mix, the image is divided into a 5 by 5 grid and the patches are randomly shuffled.\\

% \bottomrule
% \end{tabularx}
% \end{table*}

% \subsection{Stage 2 detector}
% \subsubsection{Image format} This captures the intra-file behavior of each execution. All accesses from all ranks are represented in a single image to reduce overhead. Without this integration, a large number of processes would generate a large number of images, increasing both time and memory overhead during the training and detection phases.  \taebin{also it it is good for capturing behaviour}Each image summarizes all access patterns into a 2 × image\_size × image\_size tensor and encodes information such as request type, time, size, and offset. Image size can be adjusted as a hyper parameter.

% In detail, the first dimension represents the type of request. Index 0 and 1 correspond to read and write operations, respectively. The second dimension represents the offset. To represent the offset in a fixed-size image, offsets are quantized to values from 0 to image\_size - 1. The original offset of 0 is mapped to 0, and the original maximum offset is mapped to image\_size - 1. This way, the second index of each pixel represents the relative offset within a file. The last dimension represents the time at which each request is issued. Similarly, for offsets, the request time is quantized into discrete values from 0 to image\_size - 1.

% The pixel value at each position (determined by request type, request offset, and request time) is calculated as the sum of the request sizes. All request sizes allocated to the same pixel are summed. The resulting values are then divided by the maximum pixel value in the entire image, scaling them to a range from 0 to 1. Consequently, the pixel values represent the relative request quantity within a file. The dtype can be adjusted as a hyperparameter, for example, using float16, float32, or float64.

% The size of a single image for one execution is calculated as dtype size × 2 × image\_size\^2. For example, if image\_size and dtype are set to 256 and float64, respectively, the image occupies 1024 KiB of memory. If image\_size and dtype are set to 64 and float16, the image size is reduced to approximately 16 KiB. This size is independent of the execution duration. It is significantly smaller than the raw text-based DXT logs, which on average accumulate to 30 MiB per second in the real HPC applications tested in this work. The data size can be reduced by a factor of 300 to 19,200 even for executions as short as 10 seconds. This substantial reduction is possible because the raw DXT logs contain a large amount of redundant information. Experimental observations of the effects of image\_size and dtype on data representation are discussed in Section 5.5.




% \subsubsection{Synthetic Anomaly Generator}

% In most HPC clusters, a large amount of normal (i.e., un-attacked) execution logs are available, making it easy to collect normal log data. However, anomalous (i.e., attacked) execution logs are typically scarce, and therefore model training must often be performed using only normal data. Previous studies across various domains have shown that anomalies can be detected by learning the patterns of normal data alone ~\cite{tax2004support,liu2008isolation,zhou2017anomaly,said2020network, liu2023simplenet}. Nonetheless, detecting subtle deviations that closely resemble normal behavior remains challenging\cite{chandola2009anomaly, pang2021deep, cai2022perturbation}. Similarly, in our experiments, learning normal execution behavior alone was insufficient to detect subtle anomalies that imitate normal patterns.

% To detect such anomalies effectively, a model should learn by comparing normal and anomalous data, capturing both normal and abnormal behaviors to identify discriminative differences. In this work, the Synthetic Anomaly Generator (SAG) is employed to provide the model with such information. SAG generates a diverse set of perturbations by combining basic perturbations, effectively covering a wide range of potential anomalous patterns in HPC application DXT logs. 

% Figure X shows a detailed view of the Stage 2 detector training pipeline. In the dataset object, the label is randomly chosen with a probability of 0.5. the label is 0 (Normal), the image bypasses the SAG module.  Conversely, if the label is 1 (Anomaly), the image is repeatedly passed through the SAG N times. The number of passes through the SAG, denoted as N, is randomly sampled from a discrete distribution A with four supports: {1,2,3,4}. The probability of each value decreases as N increases. This means that slightly perturbed samples occur more frequently, while severely perturbed samples are relatively rare. This design aims to provide more training samples near the decision boundary, allowing the model to learn the boundary more precisely and discern anomalies that closely resemble normal patterns.

% When an image enters the SAG module, a perturbation function is randomly selected. Subsequently, the parameters controlling the perturbation in detail are also randomly sampled from the corresponding parameter space of the chosen function. The image is then processed by the perturbation function. Even if the same function and parameters are selected by chance, the stochastic components within each function can produce different results. As training epochs progress, the model is exposed to a diverse range of anomalous patterns, increasing the likelihood of covering the I/O access patterns that it aims to detect during the detection phase. Table X summarizes each perturbation function. Experimental observations regarding these functions are described in Section X.X.




% \begin{figure}[t]
%     \centering
%     \includegraphics[width=8.5cm]{Figures/3. Design_LMT_Detection.pdf}
%     \vspace{-0.6cm}
%     \caption{Overall Architecture}
%     \label{Back_hpc_architecture}
%     \vspace{-.6cm}
% \end{figure}




% \subsection{ML-based anomaly detection}



% \subsubsection{Image generation}






% \subsubsection{Image-based anomaly detection}