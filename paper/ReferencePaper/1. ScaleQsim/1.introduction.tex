\section{Introduction}
%\vspace{-.1cm}

%\skim{\textbf{WE NEED TO BE CONSISTENT ABOUT 1) qubit state or 2) qubit state space, and 3) qubit state vector. I also think 3 is correct wording, but we need to introduce the readers that qubit is represented using vector before saying state vector.....}}
Quantum computers have been advancing rapidly, achieving quantum supremacy by
outperforming classical computers on specific tasks.~\cite{arute2019quantum, markov2018quantum}.
Unlike classical computers that utilize binary bits defined by 0 and 1, quantum computers
operate with qubits. Each qubit represents a quantum state, which is mathematically
expressed as a vector called a state vector that describes its probability amplitudes
(e.g., $|\psi\rangle = \alpha|0\rangle + \beta|1\rangle$, where $\alpha$ and $\beta$
are complex amplitudes). Qubits utilize the fundamental principles of superposition
and entanglement to adopt a different computational approach from existing methods.
Superposition allows qubits to represent both 0 and 1 simultaneously, enabling faster
parallel computation~\cite{miguel2023enhancing, renner2022computational,
yuan2022tower}. Entanglement enables unique interactions between qubits, allowing
efficient information transmission and processing~\cite{graham2022multi, mooney2019entanglement}.
These properties offer potential advantages in areas such as quantum
cryptography~\cite{bennett1992experimental, broadbent2016quantum,
pirandola2020advances, bennett2014quantum, bernstein2017post}, quantum simulations~\cite{childs2018toward,
georgescu2014quantum, daley2022practical}, and quantum machine learning~\cite{biamonte2017quantum,
schuld2015introduction, cerezo2022challenges, ramezani2020machine,
khan2020machine}, beyond the capabilities of classical computers.

Despite achieving supremacy in certain limited tasks, quantum computers are
still a long way from being adopted as the main computing platform for general
or even specific applications. This is because current quantum computers are classified
as Noisy Intermediate-Scale Quantum (NISQ) devices that are susceptible to the high
error rates inherent in quantum systems. This limitation makes them highly
susceptible to accumulated noise and errors, preventing them from producing reliable
and consistent output~\cite{preskill2018quantum, saki2019study, lau2022nisq}. In
addition, NISQ computers require extremely low temperatures to operate, which
limits accessibility and increases operational costs~\cite{martin2022energy, grurl2020considering}.

To overcome the limitations of NISQ computers, quantum circuit simulation on High-Performance
Computing (HPC) systems has emerged. Simulating a quantum circuit and quantum
state throughout the circuit using HPC systems produces accurate and
deterministic results, free from the noise that affects physical quantum computers.
This accurate simulation is critical for developing quantum hardware and
algorithms, as well as supporting hybrid quantum-classical computing systems~\cite{fan2022hybrid,
lubinski2022advancing, li2017hybrid}. HPC systems are equipped with massive
computational resources, including powerful CPUs, GPUs, and large memory pools,
making them suitable for efficiently simulating complex quantum circuits~\cite{guerreschi2020intel,
doi2019quantum, mandra2021hybridq, li2021sv, wang2021quantum}.
%The most widely used approaches are the Schrodinger-style~\cite{feit1982solution} and the Feynman-style~\cite{feynman2018space}.
The most widely adopted simulation approaches are amplitude sampling and full state
vector simulation. Amplitude sampling approximates the amplitudes of the output
qubits. By evaluating the entire quantum circuit while retaining only the amplitudes
of the final output qubits it reduces memory usage at the cost of accuracy. In
contrast, full state vector simulation explicitly simulates the amplitudes of all
qubits, ensuring an exact simulation with no loss of accuracy. Accurately simulating
the entire qubit state enables the development of correct quantum computers and algorithms~\cite{huang2019statistical,
daley2022practical}. Our work focuses on full state vector simulation, as it is the
most accurate and widely adopted quantum simulation method.

\begin{figure}[!t]
    \centering
    \includegraphics[width=10.5cm]{figures/intro_test_file.png}
    %\vspace{-.3cm}
    \caption{Simulation time of \ScaleQsim (Proposed), SOTA (\textit{cusvaer},
    \textit{HyQuas}, \textit{Atlas}), and \textit{Qsim} (Existing), executed on 128
    GPUs using the QFT circuits (log-scale).}
    \label{intro_data_overall}
    %\vspace{-.5cm}
\end{figure}

\begin{comment}
    \noindent\textbf{Schrödinger-style: }The Schrödinger-style approach directly operates on the full state vector of size \(2^n\), avoiding the overhead of tracking all computational paths or decomposing the circuit into tensor networks. Unlike tensor network models, which often rely on approximation depending on circuit structure, it preserves full accuracy for any circuit. It also uses memory more efficiently than the Feynman-style, maintaining a single state vector instead of tracking all possible computational paths.
\textbf{\textbf{\textbf{}}}
\noindent\textbf{Feynman-style:} The Feynman-style approach simulates circuits by enumerating all possible computational paths. This allows fine-grained analysis of quantum interference and provides interpretability for understanding circuit behavior, especially in early quantum algorithms or low-qubit systems. However, the number of computational paths grows exponentially with the number of qubits, resulting in high memory consumption and increased runtimes.
\end{comment}
\begin{comment}


\noindent\textbf{Schrödinger-style: }The Schrödinger-style directly operates on the full state vector of size \(2^n\), preserving full accuracy for any circuit without relying on structural approximations. Unlike tensor network models, it avoids decomposition and maintains a single state vector, using memory more efficiently than the Feynman-style.

\noindent\textbf{Feynman-style: }The Feynman-style simulates circuits by enumerating all computational paths, offering interpretability and detailed analysis of quantum interference, particularly in low-qubit systems. However, its exponential path growth leads to high memory usage and longer runtimes.

\end{comment}
%\skim{Is this part really necessray...? schrodinger and feynman style are not mentioned later. not sure this is important detail that we need to mention at the intro. or even entire manuscript..}

%\noindent\textbf{Tensor network model :} The tensor network model approach addresses scalability by compactly representing entanglement, enabling larger simulations for circuits with limited correlations. However, they rely on circuit-dependent approximations and complex tensor operations, which can reduce accuracy and limit general applicability.

%However, memory demand still increases exponentially as the number of qubits increases.

\begin{comment}
\changjong{
As a result, quantum circuit simulation using HPC systems has emerged as a critical research area. HPC systems are equipped with massive computational resources, including powerful CPUs, GPUs, and large memory pools~\cite{guerreschi2020intel, doi2019quantum, mandra2021hybridq, li2021sv, wang2021quantum}. These capabilities make them suitable for efficiently simulating complex quantum circuits. By effectively parallelizing quantum circuit simulations, HPC systems can significantly reduce runtime and enhance simulation efficiency. For example, high-performance quantum simulation libraries such as Google Qsim, Nvidia cuQuantum, Pennylane, and IBM Qiskit are widely used to maximize performance on HPC systems~\cite{qsim, bayraktar2023cuquantum, bergholm2018pennylane, cross2018ibm}.
Despite using high-performance quantum simulation libraries, performance and scalability issues still remain limited by the simulation approach. The most widely used approaches are the Schrodinger-style~\cite{feit1982solution}, Feynman-style~\cite{feynman2018space}, and tensor network model~\cite{markov2008simulating}. The Feynman-style approach is inefficient due to the need to store or compute all possible paths, leading to extremely high memory usage and runtime.
Tensor network model approach address scalability by compactly representing entanglement, enabling larger simulations for circuits with limited correlations. However, they rely on circuit-dependent approximations and complex tensor operations, which can reduce accuracy and limit general applicability. In contrast, the Schrödinger-style approach directly operates on the full state vector of size \(2^n\), avoiding the overhead of tracking all computational paths or decomposing the circuit into tensor networks. Unlike tensor network models, which often rely on approximation depending on circuit structure, it preserves full accuracy for any circuit. It also uses memory more efficiently than the Feynman-style, as it maintains a single state vector instead of tracking all possible computational paths.
However, memory demand still increases exponentially as the number of qubits increases.}
\end{comment}

To support quantum circuit simulation in HPC, high-performance quantum simulation
libraries such as Google Qsim, NVIDIA cuQuantum, Pennylane, and IBM Qiskit are
widely used to maximize performance on HPC systems~\cite{qsim, bayraktar2023cuquantum,
bergholm2018pennylane, cross2018ibm}. These frameworks utilize GPUs, which offer
higher performance than CPUs, and parallelize qubit simulations to efficiently simulate
exponentially growing qubits~\cite{ahmadzadeh2024performance, jones2019quest}. %\skim{add cite,, https://link.springer.com/article/10.1007/s11128-024-04580-x}
However, despite efforts, the existing frameworks show limited performance and scalability,
which becomes especially critical as the complexity grows exponentially with the
increasing number of qubits. Figure~\ref{intro_data_overall} shows the simulation
time comparison of the proposed \ScaleQsim, SOTA (\textit{cusvaer}~\cite{bayraktar2023cuquantum},
\textit{HyQuas}~\cite{zhang2021hyquas}, \textit{Atlas}~\cite{xu2024atlas}), and
\textit{Qsim}~\cite{qsim} framework, running the QFT circuits on an HPC system
equipped with 128 GPUs. As shown in the figure, at 32 qubits, \textit{Qsim} only
supports single-GPU and cannot perform the simulation beyond 32 qubits due to
the limited GPU memory. \textit{cusvaer} shows limited scalability, as simulations
with more qubits require multiple nodes and GPUs, which increases communication
and data management overhead. In addition, both \textit{HyQuas} and \textit{Atlas}
exhibit limited scalability due to their static designs. \textit{HyQuas} shows
lower performance compared to \ScaleQsim and fails to execute beyond 36 qubits, even
with an identical number of GPUs. The failure is due to its reliance on
precompiled kernels, which cannot fit within an individual GPU as the problem size
grows. In contrast, \textit{Atlas} shows better performance than \ScaleQsim at
35 qubits but fails to execute simulation at other qubit counts because its
configuration is strictly bound to a specific combination of the number of
qubits and GPUs (35 qubits and 128 GPUs). To summarize, addressing the poor
performance (\textit{cusvaer}, \textit{Qsim}, \textit{HyQuas}) and memory underutilization
(\textit{HyQuas}, \textit{Atlas}) of SOTA simulators, our work (\ScaleQsim) aims
to provide fast, scalable performance for more qubits while fully utilizing
available resources.

%To overcome the current limitations of SOTA simulations that 1) shows poor performacne\textit{cusvaer}~\cite{bayraktar2023cuquantum,qsim} and 2) does not fully uitilize avialble memory in GPUs~\cite{zhang2021hyquas,xu2024atlas} , our work, \ScaleQsim, aims to provide fast, scalable performance and support a higher number of qubits, even with a limited number of GPUs.

%\skim{Consider removing this part??}
%\textbf{In both cases, as the number of qubits increases, these precompiled kernels and predefined simulation plans exceed GPU memory capacity, causing the simulations to fail and exhibit limited scalability. By evenly distributing the state vector and performing %dynamic kernel execution, the proposed \ScaleQsim consistently outperforms and supports a higher number of qubits with an identical hardware setup compared with \textit{cusvaer},\textit{HyQuas}, and \textit{Atlas}.}
%\skim{And replace with this}

\begin{comment}
Additionally, \textit{HyQuas} shows faster performance than \textit{cusvaer} in specific cases (e.g., 32-36 qubit ranges). \textit{HyQuas} successfully runs simulations up to 36 qubits (10.1s), but fails at 38 and 40 qubits due to the use of precompiled CUDA kernels with fixed local qubit configurations (e.g., 28 qubits). This is because kernel parameters and shared memory usage are statically defined, which limits support for larger or deeper circuits. 
However, \textit{Atlas} fails in all 128-GPU configurations due to static scheduling and kernel structure. This is because it requires fixed gate-to-qubit mappings and predefined hardware configurations when generating execution schedules.     
\end{comment}

\begin{table}[t]
    \captionsetup{skip=2pt} % caption 아래 간격 줄이기
    \caption{Categories and comparison with previous studies (SSP: State Space
    Partitioning, DTS: Dynamic Task Scheduling, EMN: Enable Multi Node).}
    \centering
    %\vspace{-0.1cm} % caption과 표 사이 여백 미세 조절
    \footnotesize
    \begin{tabular}{p{4.0cm}|>{\raggedright\arraybackslash}p{4.5cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}}
        \toprule \textbf{Study}                                & \textbf{Method}    & \textbf{SSP} & \textbf{DTS} & \textbf{EMN} \\
        \midrule Park \textit{et al.}~\cite{park2022snuqs}     & Full state vector  &              &              &              \\
        Xu \textit{et al.}~\cite{xu2024atlas}                  & Full state vector  & \checkmark   &              & \checkmark   \\
        Burgholzer \textit{et al.}~\cite{burgholzer2021hybrid} & Hybrid             &              &              & \checkmark   \\
        Fu \textit{et al.}~\cite{fu2024achieving}              & Amplitude sampling &              &              & \checkmark   \\
        Zhang \textit{et al.}~\cite{zhang2021hyquas}           & Full state vector  & \checkmark   &              & \checkmark   \\
        Lykov \textit{et al.}~\cite{lykov2022tensor}           & Amplitude sampling &              &              & \checkmark   \\
        Westrick \textit{et al.}~\cite{westrick2024grafeyn}    & Hybrid             &              &              & \checkmark   \\
        Nguyen \textit{et al.}~\cite{nguyen2022tensor}         & Amplitude sampling &              &              & \checkmark   \\
        Häner \textit{et al.}~\cite{haner20175}                & Full state vector  & \checkmark   &              & \checkmark   \\
        \textbf{\ScaleQsim}                                    & Full state vector  & \checkmark   & \checkmark   & \checkmark   \\
        \bottomrule
    \end{tabular}
    \label{intro_table}
    %\vspace{-0.4cm}  % 아래 문단과 여백 조절 (겹침 없이 타이트하게)
\end{table}

\begin{comment}


\begin{table}[t]
\footnotesize
\small
\caption{Categories and comparison with previous studies (SSP: Scalable State Partitioning, DTS: Dynamic Task Scheduling, EMN: Enable Multi Node).}
\centering
\begin{tabular}{p{4.0cm}|>{\raggedright\arraybackslash}p{4.5cm}|p{1cm}|p{1cm}|p{1cm}}
\toprule
\textbf{Study} & \textbf{Method} & \textbf{SSP} & \textbf{DTS} & \textbf{EMN} \\
\midrule
park \textit{et al.}~\cite{park2022snuqs} & Schrödinger & & \checkmark & \\
Xu \textit{et al.}~\cite{xu2024atlas} & Schrödinger & \checkmark & \checkmark & \checkmark \\
burgholzer \textit{et al.}~\cite{burgholzer2021hybrid} & Schrödinger+Feynman & & & \\
Fu \textit{et al.}~\cite{fu2024achieving} & Tensor Network & & & \checkmark \\
Zhang \textit{et al.}~\cite{zhang2021hyquas} & Schrödinger & \checkmark & \checkmark & \checkmark \\
lykov \textit{et al.}~\cite{lykov2022tensor} & Tensor Network & & \checkmark & \checkmark \\
Westrick \textit{et al.}~\cite{westrick2024grafeyn} & Schrödinger+Feynman & & \checkmark & \\
Nguyen \textit{et al.}~\cite{nguyen2022tensor} & Tensor Network & & \checkmark & \\
Häner \textit{et al.}~\cite{haner20175} & Schrödinger & & \checkmark & \checkmark \\
\textbf{\ScaleQsim} & Schrödinger & \checkmark & \checkmark & \checkmark \\
\bottomrule
\end{tabular}

\label{intro_table}
\end{table}
    
\end{comment}

Many previous studies, as shown in Table~\ref{intro_table}, have focused on optimizing
quantum circuit simulation from different architecture and algorithm perspectives.
For example, recent studies~\cite{park2022snuqs, xu2024atlas, zhang2021hyquas, haner20175}
based on full state vector simulation address memory scalability by introducing storage-based
partitioning, hierarchical memory allocation, or multi-node execution to simulate
circuits beyond the limits of GPU memory. Other studies mitigate the
computational bottleneck by adopting fine-grained task scheduling, GPU-aware kernel
tuning, or hierarchical execution frameworks that divide and conquer large
circuits through distributed architectures~\cite{xu2024atlas, zhang2021hyquas}. In
addition, some studies adopt hybrid amplitude sampling and full state simulation
to reduce simulation complexity by limiting the number of computational paths, particularly
in sparse quantum circuits~\cite{burgholzer2021hybrid, westrick2024grafeyn}.
Other works use amplitude sampling-based approaches to improve scalability by
approximating qubit states through structured tensor contractions, which can reduce
both memory and computation requirements~\cite{fu2024achieving, lykov2022tensor,
nguyen2022tensor}.

\ScaleQsim distinguishes itself from previous studies by implementing a scalable
full state vector simulation framework for a leadership-scale HPC system.
Previous studies, such as \textit{Atlas}~\cite{xu2024atlas} and \textit{HyQuas}~\cite{zhang2021hyquas},
divide quantum circuits into sub-circuits and rely on statically generated
simulation plans with fixed gate-to-qubit mappings, kernel configurations, and
hardware-dependent schedules, limiting scalability and adaptability. In contrast,
\ScaleQsim performs dynamic execution planning during runtime. It evenly
distributes the full state vector across multiple nodes and GPUs, computes the position
of the affected state vector in runtime, schedules gate operations, and configures
kernel parameters based on the workload and available resources. When accessing
a distributed specific state vector, it utilizes distributed metadata for remote
data access and a scalable communication protocol (i.e., MPI and CUDA P2P). Our
design prevents workload skewness and eliminates the need for precompiled
kernels or precomputed simulation plans, enabling scalable performance across diverse
hardware configurations and qubits.

%\skim{
%\textbf{I think this part is incorrest as it is not the first work. Think of other points that make scaleqsim the first work or let's think about removing this part as we already said opensource at the end of intro.}

%\ScaleQsim is the first open-source framework for large-scale quantum circuit simulation, evaluated with a large number of qubits in a production HPC environment, outperforming other open/closed-source simulation frameworks.
%}

%\ScaleQsim enables large-scale quantum circuit simulation by partitioning the full state vector across distributed resources and reducing synchronization overhead by globally managing the positions of all state vector elements and broadcasting structured metadata to all nodes.
%\skim{removed consistent execution as it is not important compared to scalablity.}
In this paper, we present \ScaleQsim, a high-performance quantum circuit simulator
designed for scalability. \ScaleQsim adopts a full state vector simulation and
integrates three key techniques to achieve performance and scalability. The goal
of \ScaleQsim is to 1) provide a unified representation of the full state vector
with efficient distribution, 2) support inter-GPU and inter-node communication
for distributing the full state vector without synchronization overhead, and 3)
reduce the communication overhead arising from the distribution. To achieve these
goals, \ScaleQsim 1) performs a two-phase partitioning, dividing the state
vector of all qubits across nodes and then among the GPUs within each node, 2)
precomputes the mapping between local GPU memory and the full state vector
across the nodes and 3) distributes the precomputed mapping required for state transitions
and utilizes scalable interconnect protocols that are widely adopted in HPC. Our
evaluation on a leadership-scale production HPC system shows that \ScaleQsim
outperforms existing SOTA frameworks by 1.11$\times$ to 77.40$\times$ and
supports simulations with a higher number of qubits using identical resources. We
open-source the code of \ScaleQsim in the following link:
\url{https://github.com/ScaleQsim/ScaleQsim.git}

%\textbf{Original}
%The goal of \ScaleQsim is (1) two-phase partitioning of the state vector across nodes and GPUs to balance memory and parallelism, (2) selective updates of the distributed state vector to reduce communication overhead, and (3) minimized inter-node communication by enabling each node to operate independently using shared global metadata.
%To achieve these goals, \ScaleQsim first performs two-phase partitioning, dividing the state vector across nodes and then among GPUs within each node. Second, each task precomputes affected state vector positions, enabling local gate execution. Third, shared global metadata describing the state layout is broadcast to all nodes for consistent, decentralized execution.

%\textbf{Revised}
%\changjong{The goal of \ScaleQsim is to 1) provide a unified representation of the full qubit states with efficient distribution, 2) support inter-GPU and inter-node communication for distributed qubit states without synchronization overhead, and 3) reduce the communication overhead arising from the distribution.
%To achieve these goals, \ScaleQsim 1) performs a two-phase partitioning, dividing the entire qubit state across nodes and then among the GPUs within each node, 2) precomputes the mapping between local GPU memory and the entire state space across the nodes and 3) distributes the precomputed mapping required for state transitions and utilizes scalable interconnect protocols that are widely adopted in HPC.
%}

\begin{comment}

SnuQS
Atlas
Full-state quantum circuit simulation by using data compression (sc'19)
Full state quantum circuit simulation beyond memory limit (ICCAD)
Hyquas: hybrid partitioner based quantum circuit simulation system on gpu (ICS 21)
0.5 petabyte simulation of a 45-qubit quantum circuit (SC'17)
HQ-Sim: High-performance State Vector Simulation of Quantum Circuits on Heterogeneous HPC Systems (QCCC'23)

Circuit Partitioning and Full Circuit Execution: A Comparative Study of GPU-Based Quantum Circuit Simulation
Q-GPU: A Recipe of Optimizations for Quantum Circuit Simulation Using GPUs (HPCA'22)
\end{comment}

\begin{comment}
#1차정리


양자 컴퓨터는 최근 급격히 발전하며, 고전 컴퓨터의 계산 능력을 초월하는 
 양자 우월성(Quantum Supremacy) 을 보여주고 있습니다. 고전 컴퓨터가 0과 1로 정의되는 이진 비트(Binary Bit)를 사용하는 것과 달리, 양자 컴퓨터는  양자 비트(큐비트, Qubit) 를 사용합니다.

큐비트는 양자 역학의 핵심 원리인 중첩(Superposition) 과  얽힘(Entanglement) 을 활용하여 기존 정보 처리 방식과는 전혀 다른 계산 방식을 채택합니다. 중첩은 큐비트가 0과 1의 두 상태를 동시에 표현할 수 있게 하여 병렬 계산을 가능하게 하며, 얽힘은 여러 큐비트 사이의 상호 의존성을 이용해 정보 전송 및 연산 과정에서 비고전적 상호작용을 가능하게 합니다. 이러한 특성은 암호학, 과학적 시뮬레이션, 기계 학습 등 다양한 분야에서 기존 컴퓨터로는 불가능한 성능 향상을 기대하게 합니다.

그러나, 현재 대부분의 양자 컴퓨터는 노이즈가 많은 중간 규모 양자 컴퓨터(NISQ, Noisy Intermediate-Scale Quantum) 로 분류됩니다. NISQ 컴퓨터는 양자 오류 수정(Quantum Error Correction)을 완전히 구현하지 못한 상태에서 소규모 큐비트 집합으로 연산을 수행하므로, 잡음과 오류의 누적으로 인해 실용적인 성능을 안정적으로 확보하기 어렵습니다. 또한, NISQ 컴퓨터는 매우 고가의 자원이기 때문에 소수의 연구 그룹만이 접근할 수 있는 한계가 있습니다.

이러한 문제를 극복하기 위해, 고성능 컴퓨팅(HPC) 시스템을 활용한 양자 회로 시뮬레이션이 중요한 연구 분야로 자리잡고 있습니다. 양자 회로 시뮬레이션을 수행하기 위해 주로  슈뢰딩거 방식(Schrodinger-style)과  파인만 방식(Feynman-style) 이 사용됩니다. 파인만 방식은 메모리 요구 사항이 적지만 실제 처리 시간이 매우 크기 때문에 널리 사용되지 않습니다. 대신, 많은 시뮬레이터는 슈뢰딩거 방식을 채택합니다.

슈뢰딩거 방식은 양자 회로의 모든 양자 상태를 크기 2n의 상태 벡터로 유지하며, 게이트 연산을 이를 기반으로 수행합니다. 즉, n개의 큐비트로 이루어진 시스템은 2n개의 복소수로 표현됩니다. 이 방식은 전체 상태를 정확히 추적할 수 있지만, 큐비트 수가 증가함에 따라 메모리 요구 사항이 기하급수적으로 증가하는 문제가 있습니다.

이를 해결하기 위해, 많은 연구에서는 상태 벡터 시뮬레이션의 성능 및 확장성을 개선하기 위해 CPU, GPU 및 병렬 구성을 활용하는 방법을 개발하고 있습니다. 또한, DRAM과 NVMe, SATA SSD와 같은 고성능 스토리지를 활용하여 상태 벡터를 저장하고 관리하는 기법도 제안되고 있습니다. 하지만, 성능 및 확장성 문제는 여전히 해결되지 않은 중요한 과제로 남아 있습니다.

----

본 논문에서는 고성능 컴퓨팅 (HPC) 시스템의 풍부한 GPU 자원을 활용한 양자 회로 시뮬레이션의 성능을 확장하기 위한 새로운 기법들을 제안합니다. 특히, 각 노드에 다수의 GPU를 포함하는 멀티 노드 아키텍처를 고려하여 슈뢰딩거 방식의 상태 백터 시뮬레이션을 효과적으로 처리합니다. 

1) 전체 상태 백터는 다수의 노드와 GPU로 분할되어 배치되며, 각 GPU는 분할된 상태 백터 공간을 연속적으로 할당을 받는다. 
2) 

본 논문에서는 
1) 상태 백터 공간 분할 
- 다중 GPU / 다중 노드를 고려한 Statespace 분할. 
2) 게이트 연산 작업 분할 
- 노드 및 GPU의 인덱스 할당 구조를 고려한 인덱스 계산
- 다중 큐비트의 조합 인덱스 계산
- 각 GPU 범위에 맞는 노드 -> GPU에 작업 할당.  
3) 게이트 연산 시, Parallel ?
- 각 GPU의 정확한 범위 트래킹, 유효 인덱스 필터링.
- 실제 GPU CUDA에서 처리할 수 있는 block, size는 제한적임. 이로 인해 다이나믹하게 실제 메모리 사용량을 트래킹 (statespace를 제외한 실제 연산에 요구되는 양)하여 최상의 성능을 이끌어내기 위한 작업. 


-----

previous studies (Task Partitioning, Multi-Node, 
우린 서킷 분할이 아님 (좀 메리트 없나?) 작업 분할임. 




\end{comment}

\begin{comment}
양자 컴퓨터는 최근 급격히 발전하면서, 많은 연구에서 고전 컴퓨터의 계산 능력을 초월하는 양자 우월성(Quantum Supremacy)을 확립하고 있다. 고전 컴퓨터가 0 또는 1로 명확히 정의되는 Binary Bit를 정보 단위로 사용하는 것과 달리, 양자 컴퓨터는 양자 비트라는 큐비트를 채택합니다. 

큐비트는 양자 역학의 핵심 원리인 중첩(Superposition)과 얽힘(Entanglement)이라는 두 가지 현상을 활용함으로써 기존의 정보 처리 방식과는 본질적으로 상이한 계산 능력을 구현합니다. 중첩의 경우, 큐비트는 고전적 비트와 달리 0과 1의 두 상태를 동시에 확률적으로 결합하여 표현할 수 있으며, 이러한 특성은 병렬 계산의 가능성을 열어줍니다. 또한, 얽힘 현상을 통해 두 개 이상의 큐비트 사이에서 발생하는 상호 의존성은 정보의 전송 및 연산 과정에서 비고전적 상호작용을 가능하게 하여, 특정 문제에 대해 지수적으로 빠른 계산을 가능하게 합니다.

이러한 특성은 암호학, 과학적 시뮬레이션, 그리고 기계 학습을 포함한 다양한 분야에서 기존 컴퓨터 아키텍처로는 도달하기 어려운 성능 향상을 기대하게 합니다. 

양자 컴퓨터는 뛰어난 계산 능력을 가지고 있음에도 불구하고, 실질적인 활용에는 여전히 많은 제약이 존재합니다. 현재 개발된 대부분의 양자 컴퓨터는 노이즈가 많은 중간 규모 양자 컴퓨터(NISQ, Noisy Intermediate-Scale Quantum)로 분류됩니다. NISQ 컴퓨터는 양자 오류 수정(Quantum Error Correction)을 완전히 구현하지 못한 상태에서 소규모 큐비트 집합으로 연산을 수행하며, 잡음과 오류의 누적으로 인해 실용적인 응용에서 기대되는 성능을 안정적으로 확보하기 어렵다는 문제가 있습니다.
또한, 많은 양자 응용 프로그램에서 요구하는 높은 수준의 robustness은 이러한 NISQ 컴퓨터가 직면하고 있는 Decoherence 문제와 오류 수정 기능의 부족으로 인해 충족되지 못하고 있습니다. 게다가, NISQ 컴퓨터는 매우 고가의 자원이기 때문에 소수의 연구 그룹 외에는 접근하기 어려운 한계를 가지고 있습니다. 이와 같은 문제를 해결하기 위해, 고성능 컴퓨팅(HPC) 시스템을 활용한 양자 시뮬레이션은 중요한 연구 분야로 자리잡고 있음. 

양자 회로 시뮬레이션을 수행하기 위해, 주로 슈뢰딩거 방식(Schrodinger-style) 과 파인만 방식(Feynman-style) 두 가지 접근 방식이 사용됩니다. 이 중, 대부분의 최첨단(SOTA) 시뮬레이터는 파인만 방식이 메모리 요구 사항이 적다는 장점이 있지만, 실제 처리 시간이 매우 크다는 단점을 가지고 있어 널리 사용되지 않습니다. 대신, 많은 시뮬레이터는 슈뢰딩거 방식을 채택합니다.

슈뢰딩거 방식은 양자 회로의 모든 양자 상태를 크기가 2^n인 상태 벡터로 유지하며, 게이트 연산을 이를 기반으로 수행합니다. 즉,n개의 큐비트를 포함하는 시스템의 상태는 2^n 개의 복소수로 이루어진 벡터로 표현됩니다. 이 방식은 전체 상태를 정확히 추적할 수 있지만, 큐비트 수가 증가함에 따라 메모리 요구 사항이 기하급수적으로 증가한다는 문제가 있습니다. 이로인해, 많은 연구에서는 상태 백터 시뮬레이션의 성능 및 확장성을 개선하기 위해 CPU, GPU 및 병렬 구성을 활용하고 있다. 또한 DRAM과 고성능 스토리지 (NVMe, SATA SSDs)와 같은 2차 저장 장치를 사용하여 상태 백터를 저장하는 기법을 개발하고 있다. 하지만 여전히 성능 및 확장성 문제를 여전히 해결되지 않은 중요한 과제이다. 




본 논문에서는 현대 GPU



\end{comment}