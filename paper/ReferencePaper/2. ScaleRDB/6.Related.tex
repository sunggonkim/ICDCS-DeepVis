%\vspace{-0.3cm}
\section{Related Works} \label{related}

%\skim{remove subsection, make as bold no indent, include all papers from the intro}

%\subsection{Distributed architecture structure for manycore system}
%OceanBase Paetica: A Hybrid Shared-Nothing/Shared-Everything Database for Supporting Single Machine and Distributed Cluster

%p2KVS: a portable 2-dimensional parallelizing framework to improve scalability of key-value stores on SSDs

%High-Performance Transaction Processing in Journaling File Systems

%ScaleFS: A multicore-scalable file system.

%\skim{ WE Need to have serpate section for Distributed database, especially for shared nothing architecture,  Cicada: Dependably Fast Multi-Core In-Memory Transaction }

\noindent\textbf{Database for Modern Hardware: } Prior work boosts parallelism either by exploiting fast storage (e.g., NVDIMM, NVMe) for workload-specific I/O paths~\cite{264834, leis2024leanstore, lee2025boosting, yang2023oceanbase, li2021leveraging, he2023database, an2023nv} or by making key-value systems NUMA-aware and splitting global key spaces for concurrency~\cite{caibonsaikv, lu2022p2kvs, leis2018leanstore, liu2023zen+, li2022numa, wagle2015numa, hong2019scaling}. Unlike component-level optimizations, \DASCALE targets the full relational stack, harnesses idle cores, and, with a shared-nothing-on-shared-memory design, distributes workloads across a single manycore system to deliver scalable performance while preserving full RDB features.


\begin{comment}
He et al.~\cite{he2023database} identified performance degradation in NVMe SSDs across six popular databases due to limited awareness of I/O size, parallelism, and sequential processing, and proposed a framework to optimize parameter tuning for performance improvement.
Leis et al.~\cite{leis2018leanstore} proposed LeanStore, an in-memory database system that employs pointer swizzling for fast access to memory-resident pages, combined with a novel page replacement policy to support efficient data management between memory and disk, enhancing scalability.
Cai et al.~\cite{caibonsaikv} proposed BonsaiKV, which reduces memory usage through hierarchical indexing between DRAM and NVMM. It improves parallel processing performance and supports scalability in large memory systems using fine-grained data striping and NUMA-aware management.
    
\end{comment}

%Unlike these studies, \DASCALE focuses on the efficient utilization of idle cores and optimization for fully featured relational databases. 

%While previous studies only optimize specific components of a database for manycore, such as I/O processing and the storage engine, \DASCALE optimizes the entire relational database through microservices architecture.
%This allows \DASCALE to support the full features of relational databases and even outperform the existing optimization as the number of threads increases.

\begin{comment}
    does not optimize the full feature of RDBS 

\DASCALE 
To do this, \DASCALE employs 
This allows \DASCALE to be applied to standalone RDBMS in a single mancyre system.


Chen et al.~\cite{264834} proposed a framework for improving database performance in multicore systems by leveraging a variety of high-performance storage devices to the distributed architectural storage tier. Yang et al.~\cite{yang2023oceanbase} proposed OceanBase's newest database engine, focusing on combining standard-alone system and distributed system characteristics based on database type. The proposed solution is a hybrid storage architecture that can interact according to individual system types and workload characteristics. Lu et al.~\cite{lu2022p2kvs} proposed a parallel framework that splits the KVS(Key Value Store)'s global key-value space into several independent subspaces. This allows threads in each core to utilize the subspace independently. 
Miao et al.~\cite{caibonsaikv} proposed Bonsai-KV, a scheme that leverages multi-core hardware characteristics and the advantages of DRAM and NVMM to implement a heterogeneous memory system, improving performance degradation due to NUMA awareness and managing data effectively. 





Utku Sirin et al.~\cite{sirin2021performance} analyzed interference arising from OLAP and OLTP workloads and hardware resources (LLC, memory bandwidth) and proposed an effective resource allocation optimization method for resource sharing.



\DASCALE is in line with these studies in terms of effectively leveraging the hardware resources of manycore systems to improve the performance of the database.
In contrast, our scheme identifies the limited performance scalability of databases operating as stand-alone and optimizes the deployment of a distributed architecture that requires multiple physical servers into a manycore system of a single machine. 
This allows us to manage concurrent transactions on a server-by-server through each core thread, to achieve reduced latency and improved performance.
\end{comment}




\noindent\textbf{Database for Distributed Architecture: } Previous studies on distributed databases center on shared-nothing designs that scale by partitioning data and computation across independent nodes. They combine sharding, distributed query processing, and replicated high availability for scalability~\cite{6313694, loesing2015design, kallman2008h, stonebraker2013voltdb, wang2015asynchronous, cubukcu2021citus, arnold2019high, chen2024tdsql}. Other work optimizes specific operations within this setting, including skew-resistant joins, recursive evaluation, and online schema migration~\cite{cheng2014robust, wang2015asynchronous, zeng2024slsm, corbett2013spanner}. More recent studies have introduced next-generation and hybrid architectures to overcome the limitations of the traditional model, adopting deterministic execution models to reduce transaction overhead, leveraging shared-storage designs for cloud elasticity, and employing hybrid architectures to accelerate skewed workloads~\cite{thomson2012calvin, cao2022polardb, wang2022case, lam2024accelerating, zhang2024towards}. \DASCALE departs from scale-out: it targets single-server bottlenecks by restructuring a monolithic RDBMS into shared-nothing on shared memory, eliminating global contention (e.g., centralized locking, I/O serialization) and exploiting manycore parallelism without network overhead.




\begin{comment}
    Previous studies on distributed databases have primarily focused on shared-nothing architectures, aiming to scale database systems by partitioning data and computation across multiple independent nodes. Several works~\cite{6313694, loesing2015design, kallman2008h, stonebraker2013voltdb, wang2015asynchronous, cubukcu2021citus, arnold2019high, chen2024tdsql} provide scalability by partitioning data across nodes for acceleration, managing distributed queries, and ensuring high availability through replication. Other studies~\cite{cheng2014robust, wang2015asynchronous, zeng2024slsm, corbett2013spanner} have also focused on optimizing specific operations within distributed architecture, such as skew-resistant joins, recursive query evaluation, and online schema migration.
Additionally, recent studies~\cite{thomson2012calvin, cao2022polardb, wang2022case, lam2024accelerating, zhang2024towards} have introduced next-generation and hybrid architectures to overcome the limitations of the traditional model, adopting deterministic execution models to reduce transaction overhead, leveraging shared-storage designs for cloud elasticity, and employing hybrid architectures to accelerate skewed workloads.


\DASCALE takes a different approach in both design goals and system scope. While previous work scales databases by adding nodes and distributing data across a cluster, \DASCALE addresses scalability bottlenecks that occur within a single server. Rather than optimizing specific operations or extending the shared-nothing model across machines, \DASCALE restructures the database into a shared-nothing on shared-memory architecture. This design eliminates global contention, including centralized locking and I/O serialization, by addressing the fundamental limitations of monolithic databases and enabling efficient use of manycore resources without incurring network overhead.

\end{comment}


\noindent\textbf{Synchronization Overhead in Database: }Prior work targets I/O paths, consistent WAL logging, fine-grained locking, parallel reads/\\writes, and reducing duplicated persistence across WAL and MySQL binlog~\cite{lee2023lru,277848, an2022avoiding, freitag2022memory, alhomssi2023scalable}. Other work optimizes transaction-processing synchronization, index recovery, checkpoints, and locking~\cite{haubenschild2020rethinking, fuchs2022sortledton, haubenschild2023lock, bottcher2020scalable, shi2023optiql}.
\DASCALE shares the objective but differs in approach. It achieves parallelism by restructuring the entire database into a shared-nothing-on-shared-memory architecture with multiple instances, and it eliminates the root cause of global contention by partitioning shared resources rather than merely optimizing the locks that protect them.

\begin{comment}
Lee et al.~\cite{lee2023lru} proposed LRU-C, which divides the LRU list into two zones to split the mutex and flush dirty pages in batches. This allows simultaneous read/write operations, reducing thread contention. 
An et al.~\cite{an2022avoiding} proposed the Write-after-read (WAR) protocol to address read stall issues in relational databases using flash storage. It resolves resource conflicts, enabling more parallel I/O operations. 
Haunschild et al.~\cite{haubenschild2020rethinking} proposed a two-stage distributed logging scheme that minimizes log flushes by detecting transactions with no page dependencies and reduces checkpointing latency by splitting data into a subset.
    
\end{comment}



%original.
%\DASCALE is consistent with these studies in terms of solving the synchronization and data redundancy problems in databases.
%In contrast, \DASCALE focuses on 1) achieving parallelism by optimizing the entire transaction processing rather than specific synchronization through multiple microservices and 2) respecting the existing synchronization while reducing redundant data during the data flush and log write.

\begin{comment}
   Lee et al.~\cite{lee2023lru} focused on the I/O serialization problem of the database and proposed a database buffer design capable of parallelizing read and write operations by separating the global mutex of the database buffer into two independent mutexes. Haubenschild et al.~\cite{haubenschild2020rethinking} proposed an ARIES algorithm to optimize transactions with low latency, such as database index recovery and checkpoints. The solution provides linear performance scalability for thread-specific transaction processing with minimal synchronization. Huang et al.~\cite{277848} Focused on data duplication and I/O overhead due to double logging in LSM-tree-based RDB(Relational Database), an optimized logging system is proposed to remove WAL (Write-ahead Log) and use only MySQL binlog and effectively transfer the log to SSTable. \changjong{
Per Fuchs et al.~\cite{fuchs2022sortledton} proposed Sortledton, a scheme using an adjacency list-based data structure to ensure consistent transaction locking and minimize deadlocks.

 In contrast, Our scheme focuses on optimizing checkpoint participation in a round-robin manner. it reduces data redundancy caused by checkpoint operations involving all data servers simultaneously, such as the 2PL(Two-Phase-Locking). In addition, the master server manages all checkpoint information, reducing the overhead of synchronization operations to maintain data consistency. This allows us to fully utilize the resources of many-core systems and provide high throughput and scalability with synchronization and checkpoint optimization. 
\end{comment}




\noindent\textbf{Application/Operation-Specific Optimizations: }Prior work proposes parallelization for specific systems or tasks: graph databases exploit distinct access and traversal patterns to utilize idle cores and improve cache behavior~\cite{chengmammoths, zhicorograph, chen2022g, buragohain2020a1, qi2024lsgraph}. WAL-centric studies reduce consistency overhead through refined logging paths and concurrency control~\cite{huang2022removing, wang2024lavastore, nguyen2025moving, xia2020taurus, oh2020demeter, kim2019border, kim2020long, zheng2023declog, kang2018s, park2017sql}. More recent work accelerates specific queries (e.g., joins) and targets application domains such as ML databases~\cite{shanbhag2020study, zhang2023scalable, freitag2020adopting, hu2020optimization, anneser2023autosteer}. \DASCALE shares the performance goal but differs in scope: it is application-agnostic, adapts across workloads without specialized access patterns, and, as shown by TPC-C and YCSB, sustains scalability and flexibility without per-application tuning.


\begin{comment}
    \noindent\textbf{Application/operation-specific optimizations: }

Previous studies have proposed novel parallelization schemes for specific databases or applications. 
For example, studies~\cite{chengmammoths, zhicorograph, chen2022g, buragohain2020a1, qi2024lsgraph} focused on graph databases, which exhibit unique transaction processing and data access patterns, and optimized processing with respect to idle core utilization and cache performance. 
Additionally, other studies~\cite{huang2022removing, wang2024lavastore, nguyen2025moving, xia2020taurus, oh2020demeter, kim2019border, kim2020long, zheng2023declog, kang2018s, park2017sql} focused on Write-Ahead Logging (WAL), which is essential for database consistency but also incurs significant overhead. 
Finally, recent studies~\cite{shanbhag2020study, zhang2023scalable, freitag2020adopting, hu2020optimization, anneser2023autosteer} optimized specific queries, such as join operations, and targeted specific applications, such as machine learning databases.


Our paper aligns with these studies in terms of emphasizing performance optimization, as they all aim to enhance efficiency within their specific domains. While Zhi et al.~\cite{zhicorograph} focus on graph processing, Kim et al.~\cite{kim2019border} on log processing, Shanbhag et al.~\cite{shanbhag2020study} on GPU applications. 
However, \DASCALE distinguishes itself by providing a database system that adapts to various workloads without being limited to specific applications. 
In addition, \DASCALE can be applied without any workload-specific access patterns, as depicted by evaluation results using complex TPC-C and YCSB workloads, maximizing performance while ensuring scalability and flexibility.

\end{comment}




\begin{comment}
Zhi et al.~\cite{zhicorograph} proposed CoroGraph, a pipeline that leverages coroutine-based prefetching vertex data, enabling nested operations. This approach increases cache efficiency and optimizes performance by effectively utilizing idle CPU cores. 
Kim et al.~\cite{kim2019border} proposed Border-Collie, a wait-free and read-optimal algorithm designed to support efficient log processing and recovery in a multi-core system. This approach optimizes CPU resources, enhancing log processing speed and scalability. 
Shanbhag et al.~\cite{shanbhag2020study} proposed a tile-based execution model that processes data in thread blocks on the GPU and utilizes shared memory to minimize global memory access. This approach efficiently leverages memory bandwidth to achieve performance improvements.    
\end{comment}


%However, these approaches are specific to the workload and problem, whereas \DASCALE optimizations can be applied without any workload-specific access patterns. 


\begin{comment}
Audrey et al.~\cite{chengmammoths} proposed Mammoth, applying fine-grained node and edge locking to efficiently handle large-scale transactions in graph data. 
Xiangyu et al.~\cite{zhicorograph} proposed a coroutine-based prefetch pipeline for cocoGraph, which prioritizes data access sharing according to static-centric and partition-centric models, maximizing core utilization and improving cache performance.
Jong-bin et al.~\cite{kim2019border} proposed a new algorithm to improve efficiency in database logging on multi-core hardware by eliminating lock contention.
Several studies have been conducted to optimize performance in databases through query optimization and parallel processing. Anil et al.~\cite{shanbhag2020study} analyzed database analysis workload performance using GPUs and CPUs, and developed the Crystal library to efficiently process query operators with GPU acceleration. Ran Rui et al.~\cite{rui2020efficient} proposed an algorithm for efficiently joining database tables by leveraging the high parallel computing power of multi-GPU environments. Han Zhang et al.~\cite{zhang2023scalable} proposed a scheduling technique for balancing the workload of join operators in online interval joins (OIJ) using OpenMLDB. 

Our paper is in line with these studies from the perspective of optimizing database performance. However, our scheme focuses on accelerating database operations by scaling the database instance at the physical hardware level, rather than optimizing individual operators (e.g., Join, Ordering, Sorting) at the query level. In addition, this approach allows for improved performance by quickly handling concurrent transactions that reflect realistic workloads, rather than being limited to specific workloads in which optimization of individual operators within a single query. 
\end{comment}








% 나머지 intro 여기에다가? 
\begin{comment}
Improving scalability by optimizing various types of databases. 

몇몇의 연구는 데이터베이스의 쿼리 최적화 및 병렬 처리를 통한 성능 최적화를 수행하였습니다. 


Anil et al : GPU와 CPU를 사용한 데이터베이스 분석 워크로드 성능 분석과 Crystal 라이브러리를 개발하여 GPU를 활용하여 쿼리 연산자를 효율적으로 처리.
Ran rui at al. : 멀티-GPU 환경의 높은 병렬 계산 능력을 활용한 데이터베이스 테이블을 효율적으로 조인하는 알고리즘을 제안. 
Han Zhang at al: OpenMLDB를 활용한 온라인 인터벌 조인(OIJ)의 각 조인 연산자의 작업 부하를 균형있게 분배하는 스케줄링 기법을 제안. 

저희 논문은 데이터베이스의 성능을 최적화한다는 관점에서 이러한 연구와 일치합니다. 이에 반해, 저희 방식은 쿼리 레벨에서의 각 연산자(i.e. Join, Order, Sort and so on.) 단위의 최적화보다는 물리적인 하드웨어 레벨에서 데이터베이스 인스턴스의 스케일을 높이면서 데이터베이스가 요청 받은 연산을 가속화합니다. 또한 이는 특정 조인, 오더 등의 연산을 넘어 현실세계의 워크로드를 포함하는 동시 다발적인 트랜잭션을 빠르게 처리하여 데이터베이스의 성능을 개선할 수 있습니다.  





Anil et al : GPU와 CPU를 사용한 데이터베이스 분석 워크로드 성능 분석과 Crystal 라이브러리를 개발하여 GPU를 활용하여 쿼리 연산자를 효율적으로 처리.
%HTAP: OLAP, OLTP 워크로드와 하드웨어 자원(LLC, 메모리 대역폭)에서 발생하는 간섭 문제를 분석하여 효과적인 리소스 할당 최적화 방식을 제안.  
%(Per fuchs at al.)sortledton: 인접 리스트 기반 데이터 구조를 사용하여 트랜잭션의 일관된 잠금과 교착상태를 최소화하였음. 
Ran rui at al. : 멀티-GPU 환경의 높은 병렬 계산 능력을 활용한 데이터베이스 테이블을 효율적으로 조인하는 알고리즘을 제안. 
Han Zhang at al: OpenMLDB를 활용한 온라인 인터벌 조인(OIJ)의 각 조인 연산자의 작업 부하를 균형있게 분배하는 스케줄링 기법을 제안. (Graph)



%Miao cai at al. Bonski-KV: 매니코어의 하드웨어 특성과 DRAM과 NVMM의 장점을 활용하여 이기종 메모리 시스템을 구현하고 NUMA 인식을 통한 메모리 접근의 성능 저하를 개선하여 데이터를 효과적으로 관리하는 스킴을 제안. (KV)
%Audrey Cheng at al. Mammoth: 그래프 데이터에서 발생하는 대규모 트랜잭션을 효율적으로 지원하기 위한 노드와 엣지 수준의 세밀한 락킹을 적용함. (Graph)
%Jongbin Kim etal : 보더콜리: Lock contention을 제거하기 위한 I/O 로깅 알고리즘을 제안, (KV)







    
\end{comment}
   
\noindent\textbf{}



%LRU-C: Parallelizing Database I/Os for flash SSDs

%Rethinking logging, checkpoints, and recovery for high-performance storage engines

%Removing Double-Logging with Passive Data Persistence in LSM-tree-based Relational Databases

