\section{Discussion and Limitation}~\label{DiscussionAndLimitation}

We critically analyze \DeepVis's security properties, limitations, and potential evasion strategies. Following the ``Dos and Don'ts of Machine Learning in Computer Security''~\cite{arp2022dos}, we explicitly evaluate robustness against adaptive attackers.

\subsection{Robustness Against Adaptive Attackers}

We assume a \textbf{white-box adversary} who knows the hash mapping function $M(f)$, the RGB encoding scheme, and the CAE architecture.

\subsubsection{Attack 1: Low-Entropy Mimicry}

An attacker might reduce their rootkit's entropy to evade the Red channel.

\noindent\textit{Attack Vector:} The attacker pads the malicious binary with English text, Base64-encoded junk, or NOP sleds to lower entropy from $S \approx 7.8$ to $S \approx 5.5$ (normal binary range).

\noindent\textit{Defense Analysis:} While this defeats the Red channel, the attack incurs significant \textbf{Attack Costs}:
\begin{enumerate}
    \item \textbf{Size Inflation:} Padding increases file size substantially. A 50KB rootkit padded to achieve $S < 6.0$ may grow to 200KB+, triggering the Green (Size) channel.
    \item \textbf{Permission Anomaly:} The malicious file still requires execution permissions. A new SUID binary in \texttt{/lib/modules/} triggers the Blue channel.
    \item \textbf{Functional Constraints:} Low-entropy encoding limits code density, potentially degrading rootkit functionality or requiring multi-stage payloads.
\end{enumerate}

We experimentally validated this by creating a ``Low-Entropy Diamorphine'' variant (padded to $S = 5.6$). \DeepVis detected it via the Green channel (file size 4.2x larger than typical kernel modules) with Local Max = 0.87.

\subsubsection{Attack 2: Chameleon Attack (Hash Collision Exploitation)}

An attacker might craft a malicious filename whose hash collides with a high-churn benign file (e.g., log files).

\noindent\textit{Attack Vector:} The attacker finds $p^*$ such that $H(p^*) = H(\texttt{/var/log/syslog})$, hoping their rootkit's signal is lost in log rotation noise.

\noindent\textit{Defense Analysis:}
\begin{enumerate}
    \item \textbf{Pre-image Resistance:} Finding a functional path $p^*$ in \texttt{/lib/modules/} that hashes to a target value requires $2^{64}$ operations (MD5 truncated). This is computationally prohibitive.
    \item \textbf{Max-Risk Pooling:} Even if collision occurs, Max-Risk Pooling surfaces the \textit{highest} entropy value. A packed rootkit ($S = 7.8$) colliding with a log file ($S = 4.2$) still shows $S = 7.8$ in the pixel.
    \item \textbf{Path Semantics:} Functional rootkit paths (\texttt{/lib/modules/*.ko}) have different path structures than log files, making targeted collisions impractical.
\end{enumerate}

\subsubsection{Game-Theoretic Analysis: The Attacker's Optimization Problem}

We model evasion as a constrained optimization game between the Attacker $\mathcal{A}$ and Defender $\mathcal{D}$.
Let $x$ be the malicious file. The attacker aims to minimize the detection probability $P_\mathcal{D}(detect|x)$ while maintaining malicious utility $U(x) > \tau$.
\DeepVis employs a multi-channel detection function $D(x) = \bigvee_{c \in \{R,G,B\}} (S_c(x) > \theta_c)$. 
The attacker must solve:
\begin{equation}
    x^* = \arg\min_{x'} \max \left( S_{ent}(x'), S_{size}(x'), S_{api}(x') \right) \quad \text{s.t. } U(x') \geq U(x)
\end{equation}
This induces a \textbf{Trilemma Cost Function} $C(x')$:
\begin{enumerate}
    \item \textbf{Entropy Cost ($C_{eng}$):} Reducing entropy requires padding or expansive encoding, increasing file size ($S_{size} \uparrow$).
    \item \textbf{Size Cost ($C_{mem}$):} Splitting payloads to reduce size increases API call density for inter-process communication ($S_{api} \uparrow$) or Permission anomalies ($S_{perm} \uparrow$).
    \item \textbf{Functionality Cost ($C_{util}$):} Removing packed/obfuscated code exposes the logic to static signatures (Risk$_{AV} \uparrow$).
\end{enumerate}
Our empirical results confirm that minimizing one cost component inevitably increases another, forcing $x^*$ into the detectable region of at least one channel.

\subsection{Comparison with Provenance-Based IDS (PIDS)}

Table~\ref{tab:pids_comparison} compares \DeepVis with state-of-the-art PIDS systems.

\begin{table}[t]
\centering
\caption{Comparison with Provenance-Based IDS}
\label{tab:pids_comparison}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccc}
\toprule
\textbf{Property} & \textbf{Unicorn} & \textbf{Kairos} & \textbf{Flash} & \textbf{DeepVis} \\
\midrule
Data Source & Audit Logs & Prov. Graph & Prov. Graph & Disk Snapshot \\
Kernel Instrumentation & Required & Required & Required & \textbf{None} \\
Memory-Only Attacks & \checkmark & \checkmark & \checkmark & $\times$ \\
Disk Persistence & $\triangle$ & $\triangle$ & $\triangle$ & \checkmark \\
Runtime Overhead & High & High & Medium & \textbf{Zero$^\dagger$} \\
Explainability & Low & Medium & Medium & \textbf{High (Visual)} \\
Deployment Complexity & High & High & High & \textbf{Low} \\
\bottomrule
\end{tabular}%
}
\vspace{0.3em}
\footnotesize{$^\dagger$Snapshot-based; scan overhead only during periodic checks.}
\end{table}

\paragraph{Complementary Roles.}
PIDS (Unicorn~\cite{unicorn}, Kairos~\cite{cheng2024kairos}, Flash~\cite{rehman2024flash}) excel at detecting behavioral anomalies and memory-only attacks through causal graph analysis. However, they require kernel-level audit logging (auditd, CamFlow), imposing 5-20\% runtime overhead~\cite{pids_overhead}. \DeepVis is \textbf{orthogonal}: it detects \textit{persistent disk artifacts} without runtime overhead, making it ideal for periodic integrity verification in performance-sensitive HPC/cloud environments.

\subsection{Optimality for Sparse Anomaly Detection}

We provide a theoretical basis for choosing Local Max ($L_\infty$) over Global MSE ($L_2$) using the Neyman-Pearson framework.

\noindent\textbf{Theorem 2 (Detector Optimality).} Consider a hypothesis test $H_0: \mathbf{y} = \mathbf{n}$ vs. $H_1: \mathbf{y} = \mathbf{n} + \mathbf{s}$, where $\mathbf{n} \sim \mathcal{N}(0, \sigma^2I)$ is background noise (legitimate updates) and $\mathbf{s}$ is a sparse attack signal ($||\mathbf{s}||_0 = k \ll N$).
As the sparsity ratio $k/N \to 0$, the $L_\infty$ norm converges to the optimal likelihood ratio test statistic for distinguishing $H_1$ from $H_0$ under unknown support.

\noindent\textit{Proof Sketch.}
The Global MSE ($L_2$) statistic is $T_{L_2} = \frac{1}{N}\sum y_i^2$. Under $H_1$, $E[T_{L_2}] = \sigma^2 + \frac{k}{N}\Delta^2$. If $k \ll N$, the signal $\frac{k}{N}\Delta^2$ vanishes below the noise variance $\text{Var}(T_{L_2})$, making $H_1$ indistinguishable from $H_0$ (The MSE Paradox).
In contrast, $T_{L_\infty} = \max |y_i|$. Under $H_1$, $T_{L_\infty} \approx \Delta$ (assuming $\Delta > 3\sigma$). This statistic is independent of $k$, ensuring consistent detection even for single-pixel attacks ($k=1$). $\square$

\subsection{Limitations}

\subsubsection{Memory-Only Rootkits}

Rootkits residing solely in RAM (volatile code injection via \texttt{ptrace}) leave no disk footprint.

\noindent\textit{Mitigation:} Deploy alongside memory forensics tools (Volatility, LiME).

\subsubsection{Low-Entropy Malware}

While rare, some malware uses low-entropy payloads (ASCII-encoded shellcode, polymorphic engines).

\noindent\textit{Mitigation:} Size and Permission channels provide secondary signals. Unusual SUID bits or unexpected size changes remain detectable.

\subsubsection{Training Data Poisoning}

If the attacker compromises the system \textit{before} baseline capture, the malicious state becomes ``normal.''

\noindent\textit{Mitigation:} Capture baselines from trusted golden images or verified clean states.

\subsubsection{Collision Density at Scale}

With very large file systems ($>100,000$ files), collision density increases. Some information may be lost.

\noindent\textit{Mitigation:} Increase image resolution ($256 \times 256$ instead of $128 \times 128$) or use 3D tensor mapping with secondary hashing.

\subsection{Deployment Considerations}

\subsubsection{Agentless Architecture}

To address TCB concerns:
\begin{enumerate}
    \item Snapshot target disk (LVM, AWS EBS)
    \item Mount read-only on trusted analysis instance
    \item Execute \DeepVis on isolated copy
\end{enumerate}

\subsubsection{Scalable Architecture: Parallel & Incremental}

To scale beyond 1 million files, purely sequential scanning is insufficient. We propose a \textbf{Parallel Asynchronous Architecture}:

\begin{enumerate}
    \item \textbf{Sharded Metadata Collection:} File system traversal (`stat`, `getxattr`) is parallelized across $K$ worker threads, each handling a distinct directory shard (e.g., `hash(path) \% K`).
    \item \textbf{Incremental Visual Update:} Instead of regenerating the entire image $I_t$, we optimize the update cost. Since Phase 1 (Baseline Comparison) yields a sparse set of changes $\Delta$, we directly update only the affected pixels:
    \begin{equation}
        I_{t}[M(f)] \leftarrow \text{MaxRisk}(\text{Feature}(f)) \quad \forall f \in \Delta
    \end{equation}
    This reduces the update complexity from $O(N)$ to $O(|\Delta|)$, making real-time monitoring feasible even on Lustre/GPFS HPC storage.
\end{enumerate}

\subsubsection{Threshold Selection}

We use the 99th percentile of training data scores as the threshold. This can be tuned based on:
\begin{itemize}
    \item Security posture (lower threshold = higher recall, more FPs)
    \item Environment stability (static servers can use tighter thresholds)
\end{itemize}
